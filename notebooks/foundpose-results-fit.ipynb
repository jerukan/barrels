{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find best pose from foundpose results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import dataclass_array as dca\n",
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pycolmap\n",
    "import quaternion\n",
    "import transforms3d as t3d\n",
    "import trimesh\n",
    "import visu3d as v3d\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"bop_toolkit\")))\n",
    "from bop_toolkit.bop_toolkit_lib.misc import get_symmetry_transformations\n",
    "\n",
    "import burybarrel.colmap_util as cutil\n",
    "from burybarrel.image import render_v3d\n",
    "from burybarrel.plotting import get_axes_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstr_path = Path(\"/scratch/jeyan/barreldata/results/barrelddt1/colmap-out/0\")\n",
    "foundpose_res_path = Path(\"/scratch/jeyan/foundpose/output_barrelddt1_raw_vitl_layer18/inference/estimated-poses.json\")\n",
    "obj_path = Path(\"/scratch/jeyan/barreldata/models3d/barrelsingle-scaled.ply\")\n",
    "\n",
    "reconstruction = pycolmap.Reconstruction(reconstr_path)\n",
    "print(reconstruction.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenevtxs, scenecols = cutil.get_pc(reconstruction)\n",
    "scenepts = v3d.Point3d(p=scenevtxs, rgb=scenecols)\n",
    "cams = cutil.get_cams_v3d(reconstruction)\n",
    "# v3d.make_fig([cams, pts3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(foundpose_res_path, \"rt\") as f:\n",
    "    foundpose_res = json.load(f)\n",
    "# for now, we just use the \"best\" hypothesis\n",
    "# pretty often though, this hypothesis sucks\n",
    "foundpose_res = list(filter(lambda x: x[\"hypothesis_id\"] == \"0\", foundpose_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2cams = []\n",
    "for res in foundpose_res:\n",
    "    R = res[\"R\"]\n",
    "    t = res[\"t\"]\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = np.reshape(t, -1)\n",
    "    obj2cams.append(T)\n",
    "obj2cams = np.array(obj2cams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.load(obj_path)\n",
    "meshvtxs = np.array(mesh.vertices)\n",
    "meshpts = v3d.Point3d(p=meshvtxs, rgb=[255, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_reconstr(scale: float, cam2worlds, obj2cams, scenevtxs):\n",
    "    \"\"\"\n",
    "    Scale a 3D reconstructed scene, its camera positions, and object positions\n",
    "    relative to the camera.\n",
    "\n",
    "    Args:\n",
    "        scale (float)\n",
    "        cam2worlds (nx4x4)\n",
    "        obj2cams (nx4x4)\n",
    "        scenevtxs (nx3)\n",
    "    \"\"\"\n",
    "    # scaled 3d\n",
    "    cam2worldscaled = np.copy(cam2worlds)\n",
    "    cam2worldscaled[:, :3, 3] *= scale\n",
    "    scenevtxsscaled = scenevtxs * scale\n",
    "    obj2worlds = cam2worldscaled @ obj2cams\n",
    "    return obj2worlds, cam2worldscaled, scenevtxsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled 3d\n",
    "scalefactor = 0.2\n",
    "obj2worlds, cam2worldscaled, scenevtxsscaled = scale_reconstr(scalefactor, cams.world_from_cam.matrix4x4, obj2cams, scenevtxs)\n",
    "tofig = []\n",
    "camscaled = cams.replace(world_from_cam=v3d.Transform.from_matrix(cam2worldscaled))\n",
    "barrelpts_trf = []\n",
    "sceneptsscaled = scenepts.replace(p=scenevtxsscaled)\n",
    "tofig.extend([sceneptsscaled, camscaled])\n",
    "for i, obj2world in enumerate(obj2worlds):\n",
    "    barrelpts_trf.append(v3d.Transform.from_matrix(obj2world) @ meshpts)\n",
    "    tofig.append(barrelpts_trf[-1])\n",
    "# v3d.make_fig(*tofig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 9\n",
    "# Image.fromarray(render_v3d(camscaled[i], dca.concat([sceneptsscaled, barrelpts_trf[i]]), radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(*data, fit_func=None, loss_func=None, cost_func=None, samp_min=10, inlier_min=10, inlier_thres=0.1, max_iter=1000, seed=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        fit_func (data -> model)\n",
    "        loss_func ((model, data) -> array): vectorized loss for individual data points\n",
    "        cost_func ((model, data) -> scalar): total cost to try to minimize\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    best_model = None\n",
    "    best_inlier_idxs = []\n",
    "    best_inliers = []\n",
    "    best_error = float(\"inf\")\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        sample_indices = rng.choice(len(data[0]), samp_min, replace=False)\n",
    "        sample = [singledata[sample_indices] for singledata in data]\n",
    "\n",
    "        model = fit_func(sample)\n",
    "\n",
    "        errors = loss_func(model, data)\n",
    "\n",
    "        inlier_idxs = np.where(errors < inlier_thres)[0]\n",
    "        n_inliers = len(inlier_idxs)\n",
    "        inliers = [singledata[inlier_idxs] for singledata in data]\n",
    "\n",
    "        total_error = cost_func(model, inliers)\n",
    "\n",
    "        if n_inliers >= inlier_min:\n",
    "            if n_inliers > len(best_inlier_idxs) or (n_inliers == len(best_inlier_idxs) and total_error < best_error):\n",
    "                best_model = model\n",
    "                best_inliers = inliers\n",
    "                best_inlier_idxs = inlier_idxs\n",
    "                best_error = total_error\n",
    "    if best_model is None:\n",
    "        raise ValueError(\"No valid model found after RANSAC\")\n",
    "    return best_model, best_inlier_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity test for the ransac function\n",
    "X = np.array([-0.848,-0.800,-0.704,-0.632,-0.488,-0.472,-0.368,-0.336,-0.280,-0.200,-0.00800,-0.0840,0.0240,0.100,0.124,0.148,0.232,0.236,0.324,0.356,0.368,0.440,0.512,0.548,0.660,0.640,0.712,0.752,0.776,0.880,0.920,0.944,-0.108,-0.168,-0.720,-0.784,-0.224,-0.604,-0.740,-0.0440,0.388,-0.0200,0.752,0.416,-0.0800,-0.348,0.988,0.776,0.680,0.880,-0.816,-0.424,-0.932,0.272,-0.556,-0.568,-0.600,-0.716,-0.796,-0.880,-0.972,-0.916,0.816,0.892,0.956,0.980,0.988,0.992,0.00400]).reshape(-1,1)\n",
    "y = np.array([-0.917,-0.833,-0.801,-0.665,-0.605,-0.545,-0.509,-0.433,-0.397,-0.281,-0.205,-0.169,-0.0531,-0.0651,0.0349,0.0829,0.0589,0.175,0.179,0.191,0.259,0.287,0.359,0.395,0.483,0.539,0.543,0.603,0.667,0.679,0.751,0.803,-0.265,-0.341,0.111,-0.113,0.547,0.791,0.551,0.347,0.975,0.943,-0.249,-0.769,-0.625,-0.861,-0.749,-0.945,-0.493,0.163,-0.469,0.0669,0.891,0.623,-0.609,-0.677,-0.721,-0.745,-0.885,-0.897,-0.969,-0.949,0.707,0.783,0.859,0.979,0.811,0.891,-0.137]).reshape(-1,1)\n",
    "\n",
    "class LinearRegressor:\n",
    "    def __init__(self):\n",
    "        self.params = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        r, _ = X.shape\n",
    "        X = np.hstack([np.ones((r, 1)), X])\n",
    "        self.params = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        r, _ = X.shape\n",
    "        X = np.hstack([np.ones((r, 1)), X])\n",
    "        return X @ self.params\n",
    "\n",
    "def fitfunc(data):\n",
    "    X = data[0]\n",
    "    y = data[1]\n",
    "    reg = LinearRegressor()\n",
    "    reg.fit(X, y)\n",
    "    return reg\n",
    "\n",
    "def lossfunc(model, data):\n",
    "    X = data[0]\n",
    "    y = data[1]\n",
    "    ypred = model.predict(X)\n",
    "    return np.abs(y - ypred).reshape(-1)\n",
    "\n",
    "def costfunc(model, data):\n",
    "    X = data[0]\n",
    "    y = data[1]\n",
    "    ypred = model.predict(X)\n",
    "    return np.sum((y - ypred) ** 2) ** 0.5\n",
    "\n",
    "model, inlieridxs = ransac(X, y, fit_func=fitfunc, loss_func=lossfunc, cost_func=costfunc, samp_min=10, inlier_min=10, inlier_thres=0.2)\n",
    "# plt.scatter(X[inlieridxs], y[inlieridxs])\n",
    "# line = np.linspace(np.min(X), np.max(X), num=100).reshape(-1, 1)\n",
    "# plt.plot(line, model.predict(line), c=\"peru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this derivative 100% has a closed form but i'm too lazy to solve for it\n",
    "# so screw it, just do gradient descent.\n",
    "def variance_from_scale(scale, data):\n",
    "    camTs = jnp.array(data[0])\n",
    "    objTs = jnp.array(data[1])\n",
    "    scaledcamTs = camTs.at[:, 0:3, 3].multiply(scale)\n",
    "    centershom = scaledcamTs @ objTs @ jnp.array([0, 0, 0, 1.0])\n",
    "    centers = centershom[:, :3]\n",
    "    # trace of cov matrix for now, i guess\n",
    "    return jnp.sum(jnp.var(centers, axis=0))\n",
    "\n",
    "class ScaleCentroidModel():\n",
    "    def __init__(self):\n",
    "        self.scale = None\n",
    "        self.mean = None\n",
    "\n",
    "    def __call__(self, data):\n",
    "        return self.predict(data)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        varfunc_data = lambda x: variance_from_scale(x, data)\n",
    "        grad_cost = grad(varfunc_data)\n",
    "        scaleinit = 1.0\n",
    "        currscale = scaleinit\n",
    "        currgrad = grad_cost(scaleinit)\n",
    "        rate = 0.01\n",
    "        eps = 1e-3\n",
    "        while jnp.abs(currgrad) > eps:\n",
    "            currgrad = grad_cost(currscale)\n",
    "            currscale -= rate * currgrad\n",
    "        self.scale = float(currscale)\n",
    "        centroids = self.predict(data)\n",
    "        self.mean = np.mean(centroids, axis=0)\n",
    "        return self\n",
    "\n",
    "    def predict(self, data):\n",
    "        cam2worlds = data[0]\n",
    "        obj2cams = data[1]\n",
    "        scaledcamTs = np.copy(cam2worlds)\n",
    "        scaledcamTs[:, 0:3, 3] *= self.scale\n",
    "        centershom = scaledcamTs @ obj2cams @ jnp.array([0, 0, 0, 1.0])\n",
    "        centers = centershom[:, :3]\n",
    "        return centers\n",
    "\n",
    "# data = (cam2world nx4x4, obj2cam nx4x4)\n",
    "def fitcams(data):\n",
    "    model = ScaleCentroidModel()\n",
    "    model.fit(data)\n",
    "    return model\n",
    "\n",
    "def camloss(model, data):\n",
    "    cents = model(data)\n",
    "    return np.linalg.norm(cents - model.mean, axis=1)\n",
    "\n",
    "def camcost(model, data):\n",
    "    cents = model(data)\n",
    "    return jnp.sum(jnp.var(cents, axis=0))\n",
    "\n",
    "model, inlieridxs = ransac(cams.world_from_cam.matrix4x4, obj2cams, fit_func=fitcams, loss_func=camloss, cost_func=camcost, samp_min=5, inlier_min=5, inlier_thres=0.15, max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.scale, inlieridxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalefactor = model.scale\n",
    "obj2worlds, cam2worldscaled, scenevtxsscaled = scale_reconstr(scalefactor, cams.world_from_cam.matrix4x4, obj2cams, scenevtxs)\n",
    "tofig = []\n",
    "camsinlier = cams.replace(world_from_cam=v3d.Transform.from_matrix(cam2worldscaled))[inlieridxs]\n",
    "obj2worldsinlier = obj2worlds[inlieridxs]\n",
    "barrelpts_trf = []\n",
    "sceneptsscaled = scenepts.replace(p=scenevtxsscaled)\n",
    "tofig.extend([sceneptsscaled, camscaled])\n",
    "for i, obj2world in enumerate(obj2worldsinlier):\n",
    "    barrelpts_trf.append(v3d.Transform.from_matrix(obj2world) @ meshpts)\n",
    "    tofig.append(barrelpts_trf[-1])\n",
    "# v3d.make_fig(*tofig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3d.make_fig(*get_axes_traces(obj2worldsinlier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qangle(q1, q2):\n",
    "    \"\"\"\n",
    "    Angle in radians between 2 quaternions.\n",
    "    https://math.stackexchange.com/questions/3572459/how-to-compute-the-orientation-error-between-two-3d-coordinate-frames\n",
    "    \"\"\"\n",
    "    qerr = q1 * q2.conjugate()\n",
    "    if qerr.w < 0:\n",
    "        qerr *= -1\n",
    "    err = np.atan2(np.sqrt(qerr.x ** 2 + qerr.y ** 2 + qerr.z ** 2), qerr.w)\n",
    "    return err\n",
    "\n",
    "def closest_quat_sym(q1, q2, syms):\n",
    "    \"\"\"\n",
    "    Use q1 as reference, brute force rotate q2 and return that.\n",
    "\n",
    "    Args:\n",
    "        syms (dict): Set of symmetry transformations, each given by a dictionary with:\n",
    "            - 'R': 3x3 ndarray with the rotation matrix.\n",
    "            - 't': 3x1 ndarray with the translation vector.\n",
    "    \"\"\"\n",
    "    errs = []\n",
    "    q2_syms = []\n",
    "    for sym in syms:\n",
    "        q2_sym = q2 * quaternion.from_rotation_matrix(sym[\"R\"])\n",
    "        errs.append(qangle(q1, q2_sym))\n",
    "        q2_syms.append(q2_sym)\n",
    "    return q2_syms[np.argmin(np.abs(errs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"/scratch/jeyan/barreldata/models3d/model_info.json\"), \"rt\") as f:\n",
    "    objinfo = json.load(f)\n",
    "symTs = get_symmetry_transformations(objinfo[\"barrelsingle-scaled.ply\"], 0.01)\n",
    "# symTs = get_symmetry_transformations({\"symmetries_continuous\":[{\"axis\":[0,0,1],\"offset\":[0,0,0]}]}, 0.01)\n",
    "R1 = t3d.euler.euler2mat(0, 0, 0)\n",
    "R2 = t3d.euler.euler2mat(0, 0, np.pi)\n",
    "best = closest_quat_sym(quaternion.from_rotation_matrix(R1), quaternion.from_rotation_matrix(R2), symTs)\n",
    "best, quaternion.as_rotation_matrix(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quatsinlier = quaternion.from_rotation_matrix(obj2worldsinlier[..., :3, :3])\n",
    "ref = quatsinlier[0]\n",
    "quatssymd = [ref]\n",
    "for otherquat in quatsinlier[1:]:\n",
    "    best = closest_quat_sym(ref, otherquat, symTs)\n",
    "    quatssymd.append(best)\n",
    "quatssymd = np.array(quatssymd)\n",
    "obj2worldsinliersym = np.copy(obj2worldsinlier)\n",
    "obj2worldsinliersym[..., :3, :3] = quaternion.as_rotation_matrix(quatssymd)\n",
    "v3d.make_fig(*get_axes_traces(obj2worldsinliersym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (n quaternions)\n",
    "def qmean(qs, weights=None):\n",
    "    \"\"\"https://stackoverflow.com/questions/12374087/average-of-multiple-quaternions\"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(qs))\n",
    "    qs = np.squeeze(qs)\n",
    "    Q = quaternion.as_float_array(qs * weights).T\n",
    "    QQ = Q @ Q.T\n",
    "    vals, vecs = np.linalg.eig(QQ)\n",
    "    avg = vecs[:, np.argmax(np.abs(vals))]\n",
    "    avg = avg / np.linalg.norm(avg)\n",
    "    return quaternion.from_float_array(avg)\n",
    "\n",
    "def qloss(model, qs):\n",
    "    qs = np.squeeze(qs)\n",
    "    return np.array([qangle(model, q) for q in qs])\n",
    "\n",
    "def qcost(model, qs):\n",
    "    qs = np.squeeze(qs)\n",
    "    return np.sum(qloss(model, qs))\n",
    "\n",
    "qmeanransac, qinliers = ransac(quatssymd, fit_func=qmean, loss_func=qloss, cost_func=qcost, samp_min=5, inlier_min=5, inlier_thres=0.1, max_iter=50)\n",
    "qmeanransac, qinliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanT = v3d.Transform(R=quaternion.as_rotation_matrix(qmeanransac), t=np.mean(v3d.Transform.from_matrix(obj2worldsinliersym).t, axis=0))\n",
    "v3d.make_fig(*get_axes_traces(obj2worldsinliersym, scale=0.5), *get_axes_traces(meanT, linewidth=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3d.make_fig(camscaled, meanT @ meshpts, sceneptsscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir = Path(\"/scratch/jeyan/barreldata/divedata/dive8/barrelddt1/rgb\")\n",
    "imgpaths = list(sorted(imgdir.glob(\"*.png\")))\n",
    "imgs = [np.array(Image.open(imgpath)) for imgpath in imgpaths]\n",
    "resdir = Path(\"/scratch/jeyan/barreldata/results/barrelddt1\")\n",
    "overlaydir = resdir / \"fit-overlays\"\n",
    "overlaydir.mkdir(exist_ok=True)\n",
    "for i, img in enumerate(imgs):\n",
    "    imgpath = imgpaths[i]\n",
    "    Image.fromarray(render_v3d(camscaled[i], meanT @ meshpts, radius=4, background=img)).save(overlaydir / f\"{imgpaths[i].stem}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2camfit = camscaled.world_from_cam.inv @ meanT[..., None]\n",
    "estposes = []\n",
    "for i, obj2cam in enumerate(obj2camfit):\n",
    "    posedata = {\n",
    "        \"img_path\": str(imgpaths[i]),\n",
    "        \"img_id\": str(i),\n",
    "        \"hypothesis_id\": \"0\",\n",
    "        \"R\": obj2cam.R.tolist(),\n",
    "        \"t\": obj2cam.t[..., None].tolist(),\n",
    "    }\n",
    "    estposes.append(posedata)\n",
    "with open(resdir / \"estimated-poses.json\", \"wt\") as f:\n",
    "    json.dump(estposes, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barrels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
