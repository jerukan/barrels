{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import cv2\n",
    "import dataclass_array as dca\n",
    "import matplotlib.pyplot as plt\n",
    "import mitsuba as mi\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pycolmap\n",
    "import pyrender\n",
    "import transforms3d as t3d\n",
    "import trimesh\n",
    "import visu3d as v3d\n",
    "\n",
    "import burybarrel.colmap_util as cutil\n",
    "from burybarrel.image import render_v3d, imgs_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_window(imgs, idx, window_size):\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "    half = window_size // 2\n",
    "    if idx >= half and idx < len(imgs) - half:\n",
    "        return imgs[idx - half:idx + half + 1]\n",
    "    elif idx >= len(imgs) - half:\n",
    "        return imgs[-window_size:]\n",
    "    else:\n",
    "        return imgs[:window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_img_quantiles(in_img, in_mask, quantiles):\n",
    "    alpha = np.sqrt(1e6 / (in_img.shape[1] * in_img.shape[0]))\n",
    "\n",
    "    if alpha < 1.0:\n",
    "        reduced_img = cv2.resize(in_img, (0, 0), fx=alpha, fy=alpha)\n",
    "        if in_mask is not None:\n",
    "            reduced_mask = cv2.resize(in_mask, (0, 0), fx=alpha, fy=alpha, interpolation=cv2.INTER_NEAREST)\n",
    "        else:\n",
    "            reduced_mask = None\n",
    "    else:\n",
    "        reduced_img = in_img\n",
    "        reduced_mask = in_mask\n",
    "\n",
    "    ch_values = []\n",
    "\n",
    "    if reduced_mask is None:\n",
    "        ch_values = reduced_img.flatten()\n",
    "    else:\n",
    "        ch_values = reduced_img[reduced_mask == 0].flatten()\n",
    "\n",
    "    ch_lim = np.quantile(ch_values, quantiles).astype(int)\n",
    "    return ch_lim\n",
    "\n",
    "def stretch_color_img(in_img, ch1_lim, ch2_lim, ch3_lim, gamma_undo):\n",
    "    # Split img channels\n",
    "    temp_rgb = cv2.split(in_img)\n",
    "    temp_rgb_out = [None, None, None]\n",
    "\n",
    "    # Stretches all channels\n",
    "    ch1_low_high_in = (ch1_lim[0], ch1_lim[1])\n",
    "    ch2_low_high_in = (ch2_lim[0], ch2_lim[1])\n",
    "    ch3_low_high_in = (ch3_lim[0], ch3_lim[1])\n",
    "    low_high_out = (0, 255)\n",
    "\n",
    "    temp_rgb_out[0] = histogram_stretch(temp_rgb[0], ch1_low_high_in, low_high_out, gamma_undo)\n",
    "    temp_rgb_out[1] = histogram_stretch(temp_rgb[1], ch2_low_high_in, low_high_out, gamma_undo)\n",
    "    temp_rgb_out[2] = histogram_stretch(temp_rgb[2], ch3_low_high_in, low_high_out, gamma_undo)\n",
    "\n",
    "    # Merge channels\n",
    "    stretched_img = cv2.merge(temp_rgb_out)\n",
    "    return stretched_img\n",
    "\n",
    "def histogram_stretch(in_img, low_high_in, low_high_out, gamma_undo):\n",
    "    # Init\n",
    "    stretched_img = np.zeros(in_img.shape, dtype=in_img.dtype)\n",
    "\n",
    "    if abs(low_high_in[1] - low_high_in[0]) < 1:\n",
    "        return in_img.copy()\n",
    "\n",
    "    # Pre-compute low/high limits between 0.0 and 1.0\n",
    "    inv_max_val = 1.0 / 255.0\n",
    "    low_high_in = (low_high_in[0] * inv_max_val, low_high_in[1] * inv_max_val)\n",
    "    low_high_out = (low_high_out[0] * inv_max_val, low_high_out[1] * inv_max_val)\n",
    "    low_high_coef = (low_high_out[1] - low_high_out[0]) / (low_high_in[1] - low_high_in[0])\n",
    "\n",
    "    # undo gamma if needed\n",
    "    if gamma_undo:\n",
    "        low_high_in = (rgb2linf(low_high_in[0]), rgb2linf(low_high_in[1]))\n",
    "        low_high_out = (rgb2linf(low_high_out[0]), rgb2linf(low_high_out[1]))\n",
    "\n",
    "    # Set-up LUT to store the mapping to apply for each intensity value\n",
    "    look_up_table = np.zeros((256,), dtype=np.uint8)\n",
    "\n",
    "    # Compute the new intensity value to apply for each initial intensity\n",
    "    for i in range(256):\n",
    "        current_intensity = i * inv_max_val\n",
    "\n",
    "        if gamma_undo:\n",
    "            current_intensity = rgb2linf(current_intensity)\n",
    "\n",
    "        out_intensity = low_high_coef * (current_intensity - low_high_in[0]) + low_high_out[0]\n",
    "\n",
    "        if gamma_undo:\n",
    "            look_up_table[i] = np.clip(255.0 * lin2rgbf(out_intensity), 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            look_up_table[i] = np.clip(255.0 * out_intensity, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Apply the intensity mapping\n",
    "    stretched_img = cv2.LUT(in_img, look_up_table)\n",
    "    return stretched_img\n",
    "\n",
    "def rgb2linf(value):\n",
    "    # gamma = 2.19921875\n",
    "    return value ** 2.19921875\n",
    "\n",
    "def lin2rgbf(value):\n",
    "    # 1.0/2.19921875 = 0.45470692\n",
    "    return value ** 0.45470692"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_window([0,1,2,3,4,5,6,7,8,9], 9, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(\"../results/dive3-depthcharge-03-04-trimmed-reconstr/corrected\")\n",
    "imgdir = Path(\"../data/dive-data/Dive3/clips/dive3-depthcharge-03-04-trimmed\")\n",
    "imgpaths, imgs = imgs_from_dir(imgdir, asarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R(x,y)=\\overline{\\bar{f}(x,y)}\\cdot\\min(\\frac{1}{\\bar{f}(x,y)},\\frac{\\text{Maxscale}}{\\bar{f}(x,y)+4\\sigma(x,y)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, img in enumerate(imgs):\n",
    "    windowimg = temporal_window(imgs, i, 13)\n",
    "    avgpx = np.median(windowimg, axis=0)\n",
    "    stdpx = np.std(windowimg, axis=0)\n",
    "    avgall = np.median(windowimg)\n",
    "    maxscale = 255\n",
    "    correction = avgall * np.min([1 / avgpx, maxscale / (avgpx + 4 * stdpx)], axis=0)\n",
    "    lightcorrected = (imgs[i] * correction).astype(np.uint8)\n",
    "    m_sat_thres = 0.001\n",
    "    quantiles = [m_sat_thres, 1.0 - m_sat_thres]\n",
    "    img = imgs[0]\n",
    "    ch1_lim = find_img_quantiles(img[:, :, 0], None, quantiles)\n",
    "    ch2_lim = find_img_quantiles(img[:, :, 1], None, quantiles)\n",
    "    ch3_lim = find_img_quantiles(img[:, :, 2], None, quantiles)\n",
    "    colcorrected = stretch_color_img(lightcorrected, ch1_lim, ch2_lim, ch3_lim, False)\n",
    "    Image.fromarray(colcorrected).save(outdir / imgpaths[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barrels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
