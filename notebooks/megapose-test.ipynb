{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from megapose.datasets.object_dataset import RigidObject, RigidObjectDataset\n",
    "from megapose.utils.load_model import NAMED_MODELS, load_named_model\n",
    "from megapose.inference.types import (\n",
    "    DetectionsType,\n",
    "    ObservationTensor,\n",
    "    PoseEstimatesType,\n",
    ")\n",
    "\n",
    "from bokeh.io import export_png\n",
    "from bokeh.plotting import gridplot\n",
    "from PIL import Image\n",
    "\n",
    "# MegaPose\n",
    "from megapose.config import LOCAL_DATA_DIR\n",
    "from megapose.datasets.object_dataset import RigidObject, RigidObjectDataset\n",
    "from megapose.datasets.scene_dataset import CameraData, ObjectData\n",
    "from megapose.inference.types import (\n",
    "    DetectionsType,\n",
    "    ObservationTensor,\n",
    "    PoseEstimatesType,\n",
    ")\n",
    "from megapose.inference.utils import make_detections_from_object_data\n",
    "from megapose.lib3d.transform import Transform\n",
    "from megapose.panda3d_renderer import Panda3dLightData\n",
    "from megapose.panda3d_renderer.panda3d_scene_renderer import Panda3dSceneRenderer\n",
    "from megapose.utils.conversion import convert_scene_observation_to_panda3d\n",
    "from megapose.utils.load_model import NAMED_MODELS, load_named_model\n",
    "from megapose.utils.logging import get_logger, set_logging_level\n",
    "from megapose.visualization.bokeh_plotter import BokehPlotter\n",
    "from megapose.visualization.utils import make_contour_overlay\n",
    "\n",
    "os.environ[\"MEGAPOSE_DATA_DIR\"] = \"/scratch/jeyan/megapose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshpath = Path(\"/scratch/jeyan/barreldata/models3d/barrelsingle-scaled-subdivide.ply\")\n",
    "rigobj = RigidObject(label=\"barrel\", mesh_path=meshpath, mesh_units=\"m\")\n",
    "rigobjds = RigidObjectDataset([rigobj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"megapose-1.0-RGB-multi-hypothesis\"\n",
    "model_info = NAMED_MODELS[model_name]\n",
    "pose_estimator = load_named_model(model_name, rigobjds).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdir = Path(\"/scratch/jeyan/barreldata/results/barrelddt1/mesh-renders-spotlight\")\n",
    "imgpaths = sorted(list(imgdir.glob(\"*.jpg\")) + list(imgdir.glob(\"*.png\")))\n",
    "# (b, c, h, w)\n",
    "imgs = np.array([np.array(Image.open(imgpath)) for imgpath in imgpaths]).transpose(0, 3, 1, 2) / 255.0\n",
    "K = np.array([\n",
    "    [1246.0, 0.0, 960.0],\n",
    "    [0.0, 1246.0, 437.5],\n",
    "    [0.0, 0.0, 1.0]\n",
    "])\n",
    "camdata = CameraData(K=K, resolution=(875, 1920))\n",
    "K_batched = np.tile(K, (len(imgs), 1, 1))\n",
    "observation = ObservationTensor(images=torch.from_numpy(imgs).float().cuda(), K=torch.from_numpy(K_batched).float().cuda())\n",
    "\n",
    "maskdir = Path(\"/scratch/jeyan/barreldata/results/barrelddt1/masks\")\n",
    "maskpaths = sorted(list(maskdir.glob(\"*.png\")))\n",
    "masks = [np.array(Image.open(imgpath)) / 255.0 for imgpath in imgpaths]\n",
    "bboxes = []\n",
    "for i, mask in enumerate(masks):\n",
    "    orig_mask_modal = np.array(Image.open(maskpaths[i])) / 255.0\n",
    "    sumvert = np.sum(orig_mask_modal, axis=0)\n",
    "    left = np.where(sumvert > 0)[0][0]\n",
    "    right = np.where(sumvert > 0)[0][-1]\n",
    "    sumhor = np.sum(orig_mask_modal, axis=1)\n",
    "    bottom = np.where(sumhor > 0)[0][0]\n",
    "    top = np.where(sumhor > 0)[0][-1]\n",
    "    # bboxes should be [x1, y1, x2, y2] in the detections data type\n",
    "    bbox = [left, top, right, bottom]\n",
    "    bboxes.append(bbox)\n",
    "bboxes = torch.from_numpy(np.array(bboxes)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_infos = pd.DataFrame(\n",
    "    dict(\n",
    "        label=\"barrel\",\n",
    "        batch_im_id=np.arange(len(imgpaths)),\n",
    "        instance_id=0,\n",
    "    )\n",
    ")\n",
    "detections = DetectionsType(infos=det_infos, bboxes=bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_infos = pd.DataFrame(\n",
    "    dict(\n",
    "        label=\"barrel\",\n",
    "        batch_im_id=np.repeat(np.arange(len(imgpaths)), 5),\n",
    "        instance_id=0,\n",
    "        hypothesis_id=np.tile(np.arange(5), len(imgpaths)),\n",
    "    )\n",
    ")\n",
    "\n",
    "foundpose_estimate_path = Path(\"/scratch/jeyan/foundpose/output_barrel/inference/estimated-poses.json\")\n",
    "with open(foundpose_estimate_path, \"rt\") as f:\n",
    "    foundpose_estimates = json.load(f)\n",
    "\n",
    "poses = []\n",
    "for i, est in enumerate(foundpose_estimates):\n",
    "    R = est[\"R\"]\n",
    "    t = est[\"t\"]\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = np.array(t).reshape(-1)\n",
    "    poses.append(T)\n",
    "poses = torch.from_numpy(np.array(poses)).float().cuda()\n",
    "coarse_poses = PoseEstimatesType(infos=pose_infos, poses=poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = pose_estimator.run_inference_pipeline(\n",
    "    observation,\n",
    "    detections=detections,\n",
    "    run_detector=False,\n",
    "    coarse_estimates=coarse_poses,\n",
    "    **model_info[\"inference_parameters\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_observation(\n",
    "    example_dir: Path,\n",
    "    load_depth: bool = False,\n",
    ") -> Tuple[np.ndarray, Union[None, np.ndarray], CameraData]:\n",
    "    camera_data = CameraData.from_json((example_dir / \"camera_data.json\").read_text())\n",
    "\n",
    "    rgb = np.array(Image.open(example_dir / \"image_rgb.png\"), dtype=np.uint8)\n",
    "    assert rgb.shape[:2] == camera_data.resolution\n",
    "\n",
    "    depth = None\n",
    "    if load_depth:\n",
    "        depth = np.array(Image.open(example_dir / \"image_depth.png\"), dtype=np.float32) / 1000\n",
    "        assert depth.shape[:2] == camera_data.resolution\n",
    "\n",
    "    return rgb, depth, camera_data\n",
    "\n",
    "def save_predictions(\n",
    "    example_dir: Path,\n",
    "    pose_estimates: PoseEstimatesType,\n",
    ") -> None:\n",
    "    labels = pose_estimates.infos[\"label\"]\n",
    "    poses = pose_estimates.poses.cpu().numpy()\n",
    "    object_data = [\n",
    "        ObjectData(label=label, TWO=Transform(pose)) for label, pose in zip(labels, poses)\n",
    "    ]\n",
    "    object_data_json = json.dumps([x.to_json() for x in object_data])\n",
    "    output_fn = example_dir / \"outputs\" / \"object_data.json\"\n",
    "    output_fn.parent.mkdir(exist_ok=True)\n",
    "    output_fn.write_text(object_data_json)\n",
    "    return\n",
    "\n",
    "def load_object_data(data_path: Path) -> List[ObjectData]:\n",
    "    object_data = json.loads(data_path.read_text())\n",
    "    object_data = [ObjectData.from_json(d) for d in object_data]\n",
    "    return object_data\n",
    "\n",
    "def make_output_visualization(\n",
    "    example_dir: Path, idx, rigobjds, rgb, camera_data\n",
    ") -> None:\n",
    "\n",
    "    camera_data.TWC = Transform(np.eye(4))\n",
    "    object_datas = load_object_data(example_dir / \"outputs\" / \"object_data.json\")\n",
    "    object_dataset = rigobjds\n",
    "\n",
    "    renderer = Panda3dSceneRenderer(object_dataset)\n",
    "\n",
    "    camera_data, object_datas = convert_scene_observation_to_panda3d(camera_data, object_datas)\n",
    "    light_datas = [\n",
    "        Panda3dLightData(\n",
    "            light_type=\"ambient\",\n",
    "            color=((1.0, 1.0, 1.0, 1)),\n",
    "        ),\n",
    "    ]\n",
    "    renderings = renderer.render_scene(\n",
    "        object_datas[idx:idx+1],\n",
    "        [camera_data],\n",
    "        light_datas,\n",
    "        render_depth=False,\n",
    "        render_binary_mask=False,\n",
    "        render_normals=False,\n",
    "        copy_arrays=True,\n",
    "    )[0]\n",
    "\n",
    "    plotter = BokehPlotter()\n",
    "\n",
    "    fig_rgb = plotter.plot_image(rgb)\n",
    "    fig_mesh_overlay = plotter.plot_overlay(rgb, renderings.rgb)\n",
    "    contour_overlay = make_contour_overlay(\n",
    "        rgb, renderings.rgb, dilate_iterations=1, color=(0, 255, 0)\n",
    "    )[\"img\"]\n",
    "    fig_contour_overlay = plotter.plot_image(contour_overlay)\n",
    "    fig_all = gridplot([[fig_rgb, fig_contour_overlay, fig_mesh_overlay]], toolbar_location=None)\n",
    "    vis_dir = example_dir / \"visualizations\"\n",
    "    vis_dir.mkdir(exist_ok=True)\n",
    "    export_png(fig_mesh_overlay, filename=vis_dir / \"mesh_overlay.png\")\n",
    "    export_png(fig_contour_overlay, filename=vis_dir / \"contour_overlay.png\")\n",
    "    export_png(fig_all, filename=vis_dir / \"all_results.png\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = Path(\"/scratch/jeyan/megapose/examples/barrel\")\n",
    "\n",
    "save_predictions(outdir, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = (imgs[0].transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "make_output_visualization(outdir, 0, rigobjds, rgb, camdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_detections_visualization(\n",
    "    example_dir: Path, rgb, detections\n",
    ") -> None:\n",
    "    plotter = BokehPlotter()\n",
    "    fig_rgb = plotter.plot_image(rgb)\n",
    "    fig_det = plotter.plot_detections(fig_rgb, detections=detections)\n",
    "    output_fn = example_dir / \"visualizations\" / \"detections.png\"\n",
    "    output_fn.parent.mkdir(exist_ok=True)\n",
    "    export_png(fig_det, filename=output_fn)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_detections_visualization(outdir, rgb, detections[0:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "megapose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
