{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import cv2\n",
    "import dataclass_array as dca\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import pycolmap\n",
    "import scipy.io\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn import linear_model\n",
    "import transforms3d as t3d\n",
    "import visu3d as v3d\n",
    "\n",
    "import barrels.colmap_util as cutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir = Path(\"../dive-data/Dive8/clips/barrelddt1\")\n",
    "# image_dir = Path(\"../dive-data/Dive8/clips/barrel1\")\n",
    "# image_dir = Path(\"../data/dive-data/Dive8/clips/barrel2\")\n",
    "image_dir = Path(\"../data/dive-data/Dive8/clips/barrel3\")\n",
    "# image_dir = Path(\"../dive-data/Dive8/clips/barrelddt3\")\n",
    "# image_dir = Path(\"../dive-data/Dive8/clips/barreltriplet\")\n",
    "\n",
    "output_path = Path(f\"../results/{image_dir.name}-reconstr\")\n",
    "img_navs = pd.read_csv(image_dir / \"frame-time-nav.csv\")\n",
    "img_navs[\"timestamp\"] = pd.to_datetime(img_navs[\"timestamp\"])\n",
    "reconstruction = pycolmap.Reconstruction(output_path / \"colmap-out/mvs/sparse\")\n",
    "print(reconstruction.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process and segment dense point cloud output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam2img = {}\n",
    "for idx, img in reconstruction.images.items():\n",
    "    cam2img[img.camera_id] = img\n",
    "\n",
    "imgid2mask = {}\n",
    "for idx, img in reconstruction.images.items():\n",
    "    imgname = Path(img.name).stem\n",
    "    maskpath = output_path / f\"masks/{imgname}_mask_1.png\"\n",
    "    if maskpath.exists():\n",
    "        imgid2mask[idx] = cv2.imread(str(maskpath), cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plypc = o3d.io.read_point_cloud(str(output_path / \"openmvs-out/scene_dense.ply\"))\n",
    "plypts = np.asarray(plypc.points)\n",
    "plycols = (np.asarray(plypc.colors) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(reconstruction.images.values())[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(reconstruction.cameras.values())[0].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = (875, 1920)\n",
    "pts, cols = cutil.get_pc(reconstruction)\n",
    "\n",
    "ptcloud = v3d.Point3d(p=pts, rgb=cols)\n",
    "ptcloud_dense = v3d.Point3d(p=plypts, rgb=plycols)\n",
    "allmats = []\n",
    "v3dcams: List[v3d.Camera] = []\n",
    "camid2v3dcam = {}\n",
    "for idx, img in reconstruction.images.items():\n",
    "    cam = reconstruction.cameras[img.camera_id]\n",
    "    foc_len = cam.focal_length\n",
    "    cam_spec = v3d.PinholeCamera.from_focal(\n",
    "        # resolution=(cam.height, cam.width),\n",
    "        resolution=(H, W),\n",
    "        focal_in_px=foc_len,\n",
    "    )\n",
    "    pmat = img.cam_from_world.matrix()\n",
    "    # R = img.cam_from_world.rotation.matrix()\n",
    "    # p = img.cam_from_world.translation\n",
    "    # T = np.eye(4)\n",
    "    # T[:3, :3] = R\n",
    "    # T[:3, 3] = p\n",
    "    # T = np.linalg.inv(np.vstack([pmat, [0, 0, 0, 1]]))\n",
    "    T = np.vstack([pmat, [0, 0, 0, 1]])\n",
    "    T = np.linalg.inv(T)\n",
    "    # T[:3, :3] = -T[:3, :3].T\n",
    "    v3dcam = v3d.Camera(\n",
    "        spec=cam_spec,\n",
    "        world_from_cam=v3d.Transform.from_matrix(T)\n",
    "    )\n",
    "    camid2v3dcam[img.camera_id] = v3dcam\n",
    "    v3dcams.append(v3dcam)\n",
    "allmats = np.array(allmats)\n",
    "v3dcams = dca.stack(v3dcams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3d.make_fig([\n",
    "    ptcloud,\n",
    "    v3dcams\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camrender = v3dcams[0].render(ptcloud_dense)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(camrender)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc_to_seg = ptcloud\n",
    "pc_to_seg = ptcloud_dense\n",
    "npts = pc_to_seg.shape[0]\n",
    "idxs = np.arange(npts)\n",
    "barrelscores = np.zeros(npts)\n",
    "floorscores = np.zeros(npts)\n",
    "for imgid, mask in imgid2mask.items():\n",
    "    img = reconstruction.images[imgid]\n",
    "    v3dcam = camid2v3dcam[img.camera_id]\n",
    "    pxpts = v3dcam.px_from_world @ pc_to_seg\n",
    "    uvs = pxpts.p\n",
    "    valid = (uvs[:, 0] >= 0) & (uvs[:, 0] <= W) & (uvs[:, 1] >= 0) & (uvs[:, 1] <= H)\n",
    "    barrelmask = mask[uvs[valid].astype(int).T[1], uvs[valid].astype(int).T[0]] > 0\n",
    "    barrelidxs = idxs[valid][barrelmask]\n",
    "    flooridxs = idxs[valid][~barrelmask]\n",
    "    barrelscores[barrelidxs] += 1\n",
    "    floorscores[flooridxs] += 1\n",
    "barrelyes = barrelscores > len(imgid2mask) / 3\n",
    "segcols = np.zeros_like(pc_to_seg.rgb)\n",
    "segcols[barrelyes] = [50, 222, 100]\n",
    "segcols[~barrelyes] = [255, 0, 0]\n",
    "segpc = v3d.Point3d(p=pc_to_seg.p, rgb=segcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3d.make_fig(segpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = pc_to_seg.p[:, 0], pc_to_seg.p[:, 1], pc_to_seg.p[:, 2]\n",
    "matdata = {\n",
    "    \"scenex\": x,\n",
    "    \"sceney\": y,\n",
    "    \"scenez\": z,\n",
    "    \"isbarrel\": barrelyes\n",
    "}\n",
    "scipy.io.savemat(output_path / f\"{image_dir.name}-dense-seg.mat\", matdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# camera positions from nav data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lat2, lon1, lon2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between two points.\n",
    "    \"\"\"\n",
    "    R = 6378.137  # Radius of earth in KM\n",
    "    dLat = lat2 * np.pi / 180 - lat1 * np.pi / 180\n",
    "    dLon = lon2 * np.pi / 180 - lon1 * np.pi / 180\n",
    "    a = np.sin(dLat / 2) * np.sin(dLat / 2) + np.cos(lat1 * np.pi / 180) * np.cos(\n",
    "        lat2 * np.pi / 180\n",
    "    ) * np.sin(dLon / 2) * np.sin(dLon / 2)\n",
    "    c = 2 * np.arctan2(a ** (1 / 2), (1 - a) ** (1 / 2))\n",
    "    d = R * c\n",
    "    return d * 1000  # meters\n",
    "\n",
    "def get_img_navrow(filename):\n",
    "    img_navrows = img_navs[img_navs[\"filename\"] == filename]\n",
    "    return img_navrows.iloc[0]\n",
    "\n",
    "def random_cylinder(x1, x2, r, npoints):\n",
    "    # generates uniformly distributed points within the volume of\n",
    "    # a defined cylinder\n",
    "    x1 = np.array(x1)\n",
    "    x2 = np.array(x2)\n",
    "    axis = x2 - x1\n",
    "    h = np.linalg.norm(axis)\n",
    "    axis = axis / h\n",
    "    axnull = scipy.linalg.null_space(np.array([axis]))\n",
    "    axnull1 = axnull[:, 0]\n",
    "    axnull2 = axnull[:, 1]\n",
    "    # sqrt radius to get uniform distribution\n",
    "    rand_r = r * np.sqrt(np.random.random(npoints))\n",
    "    rand_theta = np.random.random(npoints) * 2 * np.pi\n",
    "    rand_h = np.random.random(npoints) * h\n",
    "    \n",
    "    cosval = np.tile(axnull1, (npoints, 1)) * rand_r[..., None] * np.cos(rand_theta)[..., None]\n",
    "    sinval = np.tile(axnull2, (npoints, 1)) * rand_r[..., None] * np.sin(rand_theta)[..., None]\n",
    "    xyzs = cosval + sinval + np.tile(x1, (npoints, 1)) + rand_h[..., None] * np.tile(axis, (npoints, 1))\n",
    "    return xyzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_navs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_row = img_navs.iloc[0]\n",
    "origin_x = origin_row[\"longitude\"]\n",
    "origin_y = origin_row[\"latitude\"]\n",
    "filename2transform = {}\n",
    "all_transforms = []\n",
    "for idx, row in img_navs.iterrows():\n",
    "    navpos = row\n",
    "    x = navpos[\"longitude\"]\n",
    "    y = navpos[\"latitude\"]\n",
    "    xdiff = haversine(origin_y, origin_y, origin_x, x)\n",
    "    ydiff = haversine(origin_y, y, origin_x, origin_x)\n",
    "    if x < origin_x:\n",
    "        xdiff *= -1\n",
    "    if y < origin_y:\n",
    "        ydiff *= -1\n",
    "    x = xdiff\n",
    "    y = ydiff\n",
    "    z = -navpos[\"depth\"]\n",
    "    yaw = navpos[\"yaw\"]\n",
    "    # yaw = navpos[\"heading\"] * np.pi / 180\n",
    "    pitch = navpos[\"pitch\"]\n",
    "    roll = navpos[\"roll\"]\n",
    "    reg2opt = np.array([\n",
    "        [0, -1, 0],\n",
    "        [0, 0, -1],\n",
    "        [1, 0, 0],\n",
    "    ])\n",
    "    # pitch was written assuming regular frame, oops\n",
    "    # roll is ambiguous, but is very small anyway, probably doesn't affect anything\n",
    "    R0 = t3d.euler.euler2mat(0, 0, yaw - np.pi/2, axes=\"sxyz\")\n",
    "    R1 = t3d.euler.euler2mat(-pitch - (20 * np.pi / 180), 0, roll, axes=\"rxyz\")\n",
    "    R = R0 @ R1\n",
    "    # R = t3d.euler.euler2mat(roll, pitch, yaw, axes=\"sxyz\")\n",
    "    # R = t3d.euler.euler2mat(yaw, pitch, roll, axes=\"rzyx\")\n",
    "    # R = t3d.euler.euler2mat(yaw, pitch, roll, axes=\"ryxz\")\n",
    "    # R = reg2opt @ R\n",
    "    T = np.eye(4)\n",
    "    T[:3, :3] = R\n",
    "    T[:3, 3] = [x, y, z]\n",
    "    all_transforms.append(T)\n",
    "    filename2transform[row[\"filename\"]] = T\n",
    "all_transforms = np.array(all_transforms)\n",
    "all_transforms[:, 2, 3] = all_transforms[:, 2, 3] - np.mean(all_transforms[:, 2, 3])\n",
    "\n",
    "cam_spec = v3d.PinholeCamera.from_focal(\n",
    "    resolution=(H, W),\n",
    "    focal_in_px=1360,\n",
    ")\n",
    "v3dnavcams = v3d.Camera(\n",
    "    spec=cam_spec,\n",
    "    world_from_cam=v3d.Transform.from_matrix(all_transforms)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = t3d.euler.euler2mat(0, 0, 0, axes=\"rzyx\")\n",
    "R = t3d.euler.euler2mat(0, 0, np.pi/4, axes=\"sxyz\") @ t3d.euler.euler2mat(np.pi/2, 0, np.pi/8, axes=\"rxyz\")\n",
    "T = np.eye(4)\n",
    "T[:3, :3] = R\n",
    "v3d.Camera(\n",
    "    spec=cam_spec,\n",
    "    world_from_cam=v3d.Transform.from_matrix(T)\n",
    ").fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v3dcams.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyl = random_cylinder([4, 0, -2], [4, 0, 1], 1, 1000000)\n",
    "\n",
    "rgb = np.zeros((cyl.shape[0], 3))\n",
    "rgb[:, 0] = ((cyl[:, 2] - np.min(cyl[:, 2])) / (np.max(cyl[:, 2]) - np.min(cyl[:, 2]))) * 255\n",
    "cylpt3d = v3d.Point3d(p=cyl, rgb=rgb)\n",
    "v3d.make_fig(\n",
    "    cylpt3d,\n",
    "    v3dnavcams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundpairs = set()\n",
    "realdists = []\n",
    "sfmdists = []\n",
    "ratiodists = []\n",
    "for imgid, img in reconstruction.images.items():\n",
    "    for imgid1, img1 in reconstruction.images.items():\n",
    "        if imgid != imgid1:\n",
    "            if (imgid, imgid1) in foundpairs or (imgid1, imgid) in foundpairs:\n",
    "                continue\n",
    "            v3dcam = camid2v3dcam[img.camera_id]\n",
    "            v3dcam1 = camid2v3dcam[img1.camera_id]\n",
    "            sfmdist = np.linalg.norm(v3dcam.world_from_cam.t - v3dcam1.world_from_cam.t)\n",
    "            navrow = get_img_navrow(img.name)\n",
    "            navrow1 = get_img_navrow(img1.name)\n",
    "            horizdist = haversine(navrow[\"latitude\"], navrow1[\"latitude\"], navrow[\"longitude\"], navrow1[\"longitude\"])\n",
    "            depthdist = np.abs(navrow[\"depth\"] - navrow1[\"depth\"])\n",
    "            realdist = np.sqrt(horizdist ** 2 + depthdist ** 2)\n",
    "            # T = filename2transform[img.name]\n",
    "            # T1 = filename2transform[img1.name]\n",
    "            # realdist = np.linalg.norm(T[:3, 3] - T1[:3, 3])\n",
    "            realdists.append(realdist)\n",
    "            sfmdists.append(sfmdist)\n",
    "            ratiodists.append(realdist / sfmdist)\n",
    "            foundpairs.add((imgid, imgid1))\n",
    "\n",
    "# X = np.array([sfmdists, np.ones_like(sfmdists)]).T\n",
    "X = np.array([sfmdists]).T\n",
    "y = np.array(realdists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = linear_model.RANSACRegressor(\n",
    "    estimator=linear_model.LinearRegression(),\n",
    "    max_trials=100,\n",
    "    min_samples=0.8,\n",
    ")\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X, y)\n",
    "ransac.fit(X, y)\n",
    "\n",
    "inlier_mask = ransac.inlier_mask_\n",
    "outlier_mask = ~inlier_mask\n",
    "\n",
    "line_X = np.arange(X.min(), X.max())[:, np.newaxis]\n",
    "line_y = lr.predict(line_X)\n",
    "line_y_ransac = ransac.predict(line_X)\n",
    "\n",
    "print(\"Estimated coefficients (linear regression, RANSAC):\")\n",
    "print(\"linreg coefficient:\", lr.coef_, \"ransac coefficient:\", ransac.estimator_.coef_)\n",
    "\n",
    "lw = 2\n",
    "plt.scatter(\n",
    "    X[inlier_mask], y[inlier_mask], color=\"yellowgreen\", marker=\".\", label=\"Inliers\"\n",
    ")\n",
    "plt.scatter(\n",
    "    X[outlier_mask], y[outlier_mask], color=\"gold\", marker=\".\", label=\"Outliers\"\n",
    ")\n",
    "plt.plot(line_X, line_y, color=\"navy\", linewidth=lw, label=\"Linear regressor\")\n",
    "plt.plot(\n",
    "    line_X,\n",
    "    line_y_ransac,\n",
    "    color=\"cornflowerblue\",\n",
    "    linewidth=lw,\n",
    "    label=\"RANSAC regressor\",\n",
    ")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"SFM distance\")\n",
    "plt.ylabel(\"Real distance (m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured = 0.8188\n",
    "lr.coef_[0] * measured , ransac.estimator_.coef_[0] * measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICP testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invT(T):\n",
    "    Tinv = np.eye(4)\n",
    "    Tinv[:3, :3] = T[:3, :3].T\n",
    "    Tinv[:3, 3] = -T[:3, :3].T @ T[:3, 3]\n",
    "    return Tinv\n",
    "\n",
    "def run_icp(source_pc, target_pc, init_pose=None, max_iters=20, tol=1e-3, verbose=False, ret_err=False):\n",
    "    src_mean = np.mean(source_pc, axis=0)\n",
    "    targ_mean = np.mean(target_pc, axis=0)\n",
    "    src_cent = source_pc - src_mean\n",
    "    targ_cent = target_pc - targ_mean\n",
    "\n",
    "    src_kd = KDTree(source_pc)\n",
    "    target_kd = KDTree(target_pc)\n",
    "\n",
    "    K = max_iters\n",
    "    allrots = []\n",
    "    allp = []\n",
    "    if init_pose is not None:\n",
    "        T = init_pose\n",
    "    else:\n",
    "        T = np.eye(4)\n",
    "    prevT = T\n",
    "    for i in range(K):\n",
    "        # _, close_idxs = target_kd.query((R @ src_cent.T).T)\n",
    "        _, close_idxs = src_kd.query((R.T @ (target_pc - p).T).T)\n",
    "        _, close_idxs = src_kd.query((R.T @ (target_pc - p).T).T)\n",
    "        src_mean_filt = np.mean(source_pc[close_idxs], axis=0)\n",
    "        z = source_pc[close_idxs] - src_mean_filt\n",
    "        m = targ_cent\n",
    "        Q = m.T @ z\n",
    "        U, S, V = np.linalg.svd(Q)  # V is returned already transposed\n",
    "        R = U @ np.diag([1, 1, np.linalg.det(U @ V)]) @ V\n",
    "        # p = np.mean(target_pc[close_idxs], axis=0) - R @ src_mean\n",
    "        p = targ_mean - R @ src_mean_filt\n",
    "        if np.allclose(prevT, T, atol=tol):\n",
    "            break\n",
    "        prevT = T\n",
    "        if i == K - 1:\n",
    "            if verbose:\n",
    "                print(f\"max iters {K} reached before tolerance {tol}\")\n",
    "    allrots.append(R)\n",
    "    allp.append(p)\n",
    "    # mean square error\n",
    "    bestdist = np.inf\n",
    "    bestrot = None\n",
    "    bestp = None\n",
    "    for R, p in zip(allrots, allp):\n",
    "        dists, _ = src_kd.query((R.T @ (target_pc - p).T).T)\n",
    "        meandists = np.mean(dists ** 2)\n",
    "        if meandists < bestdist:\n",
    "            bestdist = meandists\n",
    "            bestrot = R\n",
    "            bestp = p\n",
    "    pose = np.eye(4)\n",
    "    # if np.isclose(bestrot, np.eye(3), atol=1e-3).all():\n",
    "    #     bestrot = np.eye(3)\n",
    "    # if np.isclose(bestp, np.zeros(3), atol=1e-4).all():\n",
    "    #     bestp = np.zeros(3)\n",
    "    pose[:3, :3] = bestrot\n",
    "    pose[:3, 3] = bestp\n",
    "    if ret_err:\n",
    "        return pose, bestdist\n",
    "    return pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform that maps corresponding points A to B in m spatial dimensions\n",
    "    Input:\n",
    "      A: Nxm numpy array of corresponding points\n",
    "      B: Nxm numpy array of corresponding points\n",
    "    Returns:\n",
    "      T: (m+1)x(m+1) homogeneous transformation matrix that maps A on to B\n",
    "      R: mxm rotation matrix\n",
    "      t: mx1 translation vector\n",
    "    '''\n",
    "\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    H = np.dot(AA.T, BB)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "       Vt[m-1,:] *= -1\n",
    "       R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    # homogeneous transformation\n",
    "    T = np.identity(m+1)\n",
    "    T[:m, :m] = R\n",
    "    T[:m, m] = t\n",
    "\n",
    "    return T, R, t\n",
    "\n",
    "\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nxm array of points\n",
    "        dst: Nxm array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances of the nearest neighbor\n",
    "        indices: dst indices of the nearest neighbor\n",
    "    '''\n",
    "\n",
    "    assert src.shape == dst.shape\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=1)\n",
    "    neigh.fit(dst)\n",
    "    distances, indices = neigh.kneighbors(src, return_distance=True)\n",
    "    return distances.ravel(), indices.ravel()\n",
    "\n",
    "\n",
    "def icp(A, B, init_pose=None, max_iterations=20, tolerance=0.001):\n",
    "    '''\n",
    "    The Iterative Closest Point method: finds best-fit transform that maps points A on to points B\n",
    "    Input:\n",
    "        A: Nxm numpy array of source mD points\n",
    "        B: Nxm numpy array of destination mD point\n",
    "        init_pose: (m+1)x(m+1) homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation that maps A on to B\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        i: number of iterations to converge\n",
    "    '''\n",
    "\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # make points homogeneous, copy them to maintain the originals\n",
    "    src = np.ones((m+1,A.shape[0]))\n",
    "    dst = np.ones((m+1,B.shape[0]))\n",
    "    src[:m,:] = np.copy(A.T)\n",
    "    dst[:m,:] = np.copy(B.T)\n",
    "\n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbors between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[:m,:].T, dst[:m,:].T)\n",
    "\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,_,_ = best_fit_transform(src[:m,:].T, dst[:m,indices].T)\n",
    "\n",
    "        # update the current source\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.mean(distances)\n",
    "        if np.abs(prev_error - mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "\n",
    "    # calculate final transformation\n",
    "    T,_,_ = best_fit_transform(A, src[:m,:].T)\n",
    "\n",
    "    return T, distances, i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
