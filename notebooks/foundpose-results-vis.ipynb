{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures galore\n",
    "\n",
    "results visualizations for paper or something idk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup, data loading needed for most visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import sys\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cv2\n",
    "import dataclass_array as dca\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mitsuba as mi\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import pycolmap\n",
    "import pyransac3d as pyrsc\n",
    "import pyrender\n",
    "import quaternion\n",
    "import scipy.interpolate\n",
    "import trimesh\n",
    "import visu3d as v3d\n",
    "import yaml\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"bop_toolkit\")))\n",
    "from bop_toolkit.bop_toolkit_lib.pose_error import vsd, mssd, mspd\n",
    "from bop_toolkit.bop_toolkit_lib.misc import get_symmetry_transformations\n",
    "from bop_toolkit.bop_toolkit_lib.renderer import create_renderer\n",
    "\n",
    "import burybarrel.colmap_util as cutil\n",
    "from burybarrel.image import render_v3d, render_models, to_contour, overlay_img_alpha\n",
    "from burybarrel.camera import RadialCamera, load_v3dcams\n",
    "from burybarrel.mesh import subdivide_mesh, recolor_mesh, segment_pc_from_mask, segment_pc_from_masks\n",
    "from burybarrel.transform import T_from_blender, T_from_translation, scale_T_translation, scale_cams, scale_pc, icp, qangle, qmean, closest_quat_sym, get_axes_rot, apply_T_xyz\n",
    "from burybarrel.plotting import get_line3d_trace, get_axes_traces, get_plane_zup, get_surface_line_traces, get_ray_trace, generate_domain, get_carree_axis, get_carree_gl, get_trimesh_traces\n",
    "from burybarrel.utils import rgb2hex, cmapvals, match_lists, invert_idxs\n",
    "from burybarrel.estimators import ransac\n",
    "from burybarrel.foundpose_fit import fitcams, camloss, camcost, qcost, qloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpdir = Path(\"/scratch/jeyan/barreldata/tmp\")\n",
    "tmpdir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/tmp\")\n",
    "# metricscsvpath = Path(\"/scratch/jeyan/barreldata/results/allmetrics.csv\")\n",
    "metricscsvpath = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results/allmetrics.csv\")\n",
    "metricsdf = pd.read_csv(metricscsvpath)\n",
    "metricsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsdf[[\"avg_vsd\", \"avg_mssd\", \"avg_mspd\", \"burial_error_depth\", \"multiview_fitted\", \"pose_type\", \"use_icp\"]].groupby([\"multiview_fitted\", \"use_icp\", \"pose_type\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtermetrics(df, name=None, multiview_fitted=None, use_icp=None, pose_type=None):\n",
    "    if multiview_fitted is not None:\n",
    "        df = df[df[\"multiview_fitted\"] == multiview_fitted]\n",
    "    if use_icp is not None:\n",
    "        df = df[df[\"use_icp\"] == use_icp]\n",
    "    if pose_type is not None:\n",
    "        df = df[df[\"pose_type\"] == pose_type]\n",
    "    if name is not None:\n",
    "        df = df[df[\"dataset\"] == name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = len(filtermetrics(metricsdf, multiview_fitted=True, use_icp=True, pose_type=\"coarse\"))\n",
    "print(f\"Number of labeled samples: {nsamples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading EVERYTHING\n",
    "datasetname = \"barrel4\"\n",
    "singledatarows = metricsdf[metricsdf[\"dataset\"] == datasetname]\n",
    "\n",
    "# multiview fit, coarse, icp\n",
    "resrow = singledatarows[singledatarows[\"multiview_fitted\"] & (singledatarows[\"pose_type\"] == \"coarse\") & singledatarows[\"use_icp\"]].iloc[0]\n",
    "datadir = Path(resrow[\"datadir\"])\n",
    "datadir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/data/input_data\") / datadir.name\n",
    "resdir = Path(resrow[\"resdir\"])\n",
    "resdir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results\") / Path(*resdir.parts[-3:])\n",
    "object_name = resrow[\"object_name\"]\n",
    "\n",
    "with open(\"../configs/blender_gt_info.yaml\", \"rt\") as f:\n",
    "    gtinfo = yaml.safe_load(f)\n",
    "with open(datadir / \"gt_obj2cam.json\", \"rt\") as f:\n",
    "    gtposes = yaml.safe_load(f)\n",
    "with open(datadir / \"info.json\", \"rt\") as f:\n",
    "    datainfo = yaml.safe_load(f)\n",
    "with open(datadir / \"camera.json\", \"rt\") as f:\n",
    "    caminfo = yaml.safe_load(f)\n",
    "with open(resdir / \"../../sam-masks/masksinfo.json\", \"rt\") as f:\n",
    "    masksinfo = yaml.safe_load(f)\n",
    "posepath = resdir / \"estimated-poses.json\"\n",
    "estinfopath = resdir / \"reconstruction-info.json\"\n",
    "with open(posepath, \"rt\") as f:\n",
    "    ests = yaml.safe_load(f)\n",
    "with open(estinfopath, \"rt\") as f:\n",
    "    estinfo = yaml.safe_load(f)\n",
    "with open(resdir / \"../../foundpose-output/inference/estimated-poses.json\", \"rt\") as f:\n",
    "    foundposeests = yaml.safe_load(f)\n",
    "cams, imgpaths = load_v3dcams(resdir / \"../../colmap-out/cam_poses.json\", img_parent=datadir / \"rgb\")\n",
    "names = [imgpath.stem for imgpath in imgpaths]\n",
    "\n",
    "densepath = resdir / \"../../openmvs-out/scene_dense_trimeshvalid.ply\"\n",
    "densetrimesh: trimesh.PointCloud = trimesh.load_mesh(densepath)\n",
    "densepc = v3d.Point3d(p=densetrimesh.vertices, rgb=densetrimesh.colors[:, :3])\n",
    "\n",
    "camspec = RadialCamera.from_jsonargs(**caminfo)\n",
    "# objdir = Path(\"/scratch/jeyan/barreldata/models3d\")\n",
    "objdir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/models3d\")\n",
    "objpath = objdir / object_name\n",
    "with open(objdir / \"model_info.json\", \"rt\") as f:\n",
    "    objinfo = yaml.safe_load(f)\n",
    "mesh: trimesh.Trimesh = trimesh.load_mesh(objpath)\n",
    "meshpc = v3d.Point3d(p=mesh.vertices, rgb=[255, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some 3d overlay wireframe visualization thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estidx = 5\n",
    "gtidx = estidx\n",
    "camidx = estidx\n",
    "# note these might be inconsistent indices, but it would depend on SAM failing\n",
    "est = ests[estidx]\n",
    "gt = gtposes[gtidx]\n",
    "colmapcam = cams[camidx]\n",
    "singlemasksinfo = next(filter(lambda x: Path(x[\"img_path\"]).stem == Path(est[\"img_path\"]).stem, masksinfo))\n",
    "estscale = estinfo[\"scalefactor\"]\n",
    "reconstr_mesh: trimesh.Trimesh = trimesh.load(resdir / \"../../openmvs-out/scene_dense_mesh_refine.ply\")\n",
    "# reconstr_mesh.vertices = reconstr_mesh.vertices * estscale\n",
    "bestidx = singlemasksinfo[\"best_idx\"]\n",
    "mask = np.array(Image.open(Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results\") / Path(*Path(singlemasksinfo[\"mask_paths\"][bestidx]).parts[-4:])).convert(\"L\"))\n",
    "# est, gt, cam, mask\n",
    "est[\"img_path\"], gt[\"img_path\"], imgpaths[camidx], singlemasksinfo[\"img_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meshvertmask = np.zeros(reconstr_mesh.vertices.shape[0], dtype=bool)\n",
    "# flooridxsmesh = invert_idxs(segment_pc_from_mask(reconstr_mesh.vertices, mask, colmapcam), reconstr_mesh.vertices.shape[0])\n",
    "# meshvertmask[flooridxsmesh] = True\n",
    "# reconstr_floor_mesh = reconstr_mesh.copy()\n",
    "# # reconstr_floor_mesh.update_vertices(meshvertmask)\n",
    "# face_mask = meshvertmask[reconstr_mesh.faces].all(axis=1)\n",
    "# reconstr_floor_mesh.update_faces(face_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshcol = np.array([255, 0, 0, 255], dtype=np.uint8)\n",
    "planecol = np.array([0, 0, 255, 255], dtype=np.uint8)\n",
    "black = np.array([0, 0, 0, 255], dtype=np.uint8)\n",
    "transparent = np.array([0, 0, 0, 0], dtype=np.uint8)\n",
    "mesh = recolor_mesh(mesh, meshcol)\n",
    "plane = trimesh.creation.box(extents=(100, 100, 0.01))\n",
    "plane = subdivide_mesh(plane, 7)\n",
    "plane = recolor_mesh(plane, planecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2cam = v3d.Transform(R=est[\"R\"], t=est[\"t\"])\n",
    "floor2cam = v3d.Transform(R=est[\"R_floor\"], t=est[\"t_floor\"])\n",
    "obj2camgt = v3d.Transform(R=gt[\"R\"], t=gt[\"t\"])\n",
    "floor2camgt = v3d.Transform(R=gt[\"R_floor\"], t=gt[\"t_floor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = v3d.Camera(spec=camspec, world_from_cam=v3d.Transform.identity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [xmin, ymin, width, height]\n",
    "crop = [0, 120, 1920, 875]\n",
    "pilcrop = [crop[0], crop[1], crop[0] + crop[2], crop[1] + crop[3]]\n",
    "bestidx = singlemasksinfo[\"best_idx\"]\n",
    "maskalpha = cv2.cvtColor(mask, cv2.COLOR_GRAY2RGBA)\n",
    "maskalpha[~(maskalpha[..., 0] > 0), 3] = 0\n",
    "\n",
    "# predicted code\n",
    "maskrgb, _, _ = render_models(cam, [mesh, plane], [obj2cam, floor2cam], light_intensity=1000, flags=pyrender.RenderFlags.FLAT)\n",
    "objmask = np.all(maskrgb == [255, 0, 0], axis=-1)\n",
    "rgb_wireframe, _, _ = render_models(cam, [recolor_mesh(plane, black)], [floor2cam], wireframe=True, flags=pyrender.RenderFlags.RGBA | pyrender.RenderFlags.FLAT)\n",
    "rgb_wireframe = rgb_wireframe * ~objmask[..., None]\n",
    "rgb_wireframe[rgb_wireframe[..., 3] > 0, 3] = 255\n",
    "rgb_primoverlay, _, _ = render_models(cam, [mesh, plane], [obj2cam, floor2cam], light_intensity=50, wireframe=False)\n",
    "# Image.fromarray(rgb_wireframe).save(tmpdir / \"rendered_wireframe.png\")\n",
    "# Image.fromarray(rgb_primoverlay).save(tmpdir / \"rendered.png\")\n",
    "# img = cv2.cvtColor(cv2.imread(est[\"img_path\"]), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(cv2.imread(str(datadir / Path(*Path(est[\"img_path\"]).parts[-2:]))), cv2.COLOR_BGR2RGB)\n",
    "if img.shape[0] == 1080 and img.shape[1] == 1920:\n",
    "    Image.fromarray(overlay_img_alpha(img, maskalpha, alpha=0.3)).crop(pilcrop).save(tmpdir / f\"rgbres_{datasetname}.png\")\n",
    "else:\n",
    "    Image.fromarray(overlay_img_alpha(img, maskalpha, alpha=0.3)).save(tmpdir / f\"rgbres_{datasetname}.png\")\n",
    "alpha = 0.6\n",
    "img = cv2.addWeighted(img, alpha, rgb_primoverlay, 1 - alpha, 0)\n",
    "# wireframewhere = np.where(rgb_wireframe[..., 3] > 0)\n",
    "# img[wireframewhere] = rgb_wireframe[wireframewhere][..., :3]\n",
    "img = overlay_img_alpha(img, rgb_wireframe)\n",
    "mesh_wireframe, _, _ = render_models(cam, [recolor_mesh(mesh, black)], [obj2cam], wireframe=True, flags=pyrender.RenderFlags.RGBA | pyrender.RenderFlags.FLAT)\n",
    "mesh_wireframe[mesh_wireframe[..., 3] > 0, 3] = 255\n",
    "img = overlay_img_alpha(img, mesh_wireframe, alpha=0.3)\n",
    "if img.shape[0] == 1080 and img.shape[1] == 1920:\n",
    "    Image.fromarray(img).crop(pilcrop).save(tmpdir / f\"rendered_overlay_{datasetname}.png\")\n",
    "else:\n",
    "    Image.fromarray(img).save(tmpdir / f\"rendered_overlay_{datasetname}.png\")\n",
    "\n",
    "# gt code\n",
    "maskrgb, _, _ = render_models(cam, [mesh, plane], [obj2camgt, floor2camgt], light_intensity=1000, flags=pyrender.RenderFlags.FLAT)\n",
    "objmask = np.all(maskrgb == [255, 0, 0], axis=-1)\n",
    "rgb_wireframe, _, _ = render_models(cam, [recolor_mesh(plane, black)], [floor2camgt], wireframe=True, flags=pyrender.RenderFlags.RGBA | pyrender.RenderFlags.FLAT)\n",
    "rgb_wireframe = rgb_wireframe * ~objmask[..., None]\n",
    "rgb_wireframe[rgb_wireframe[..., 3] > 0, 3] = 255\n",
    "rgb_primoverlay, _, _ = render_models(cam, [mesh, plane], [obj2camgt, floor2camgt], light_intensity=50, wireframe=False)\n",
    "# Image.fromarray(rgb_wireframe).save(tmpdir / \"rendered_wireframe_gt.png\")\n",
    "# Image.fromarray(rgb_primoverlay).save(tmpdir / \"rendered_gt.png\")\n",
    "# img = cv2.cvtColor(cv2.imread(est[\"img_path\"]), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(cv2.imread(str(datadir / Path(*Path(est[\"img_path\"]).parts[-2:]))), cv2.COLOR_BGR2RGB)\n",
    "alpha = 0.6\n",
    "img = cv2.addWeighted(img, alpha, rgb_primoverlay, 1 - alpha, 0)\n",
    "# wireframewhere = np.where(rgb_wireframe[..., 3] > 0)\n",
    "# img[wireframewhere] = rgb_wireframe[wireframewhere][..., :3]\n",
    "img = overlay_img_alpha(img, rgb_wireframe)\n",
    "mesh_wireframe, _, _ = render_models(cam, [recolor_mesh(mesh, black)], [obj2camgt], wireframe=True, flags=pyrender.RenderFlags.RGBA | pyrender.RenderFlags.FLAT)\n",
    "mesh_wireframe[mesh_wireframe[..., 3] > 0, 3] = 255\n",
    "img = overlay_img_alpha(img, mesh_wireframe, alpha=0.3)\n",
    "if img.shape[0] == 1080 and img.shape[1] == 1920:\n",
    "    Image.fromarray(img).crop(pilcrop).save(tmpdir / f\"rendered_overlay_{datasetname}_gt.png\")\n",
    "else:\n",
    "    Image.fromarray(img).save(tmpdir / f\"rendered_overlay_{datasetname}_gt.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "singlemasksinfo = masksinfo[idx]\n",
    "singlemasksinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestidx = singlemasksinfo[\"best_idx\"]\n",
    "# [x_min, y_min, x_max, y_max]\n",
    "bbox = list(map(int, singlemasksinfo[\"bboxes\"][bestidx]))\n",
    "mask = np.array(Image.open(singlemasksinfo[\"mask_paths\"][bestidx]).convert(\"L\"))\n",
    "maskbool = mask > 0\n",
    "img = np.array(Image.open(singlemasksinfo[\"img_path\"]).convert(\"RGBA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskalpha = np.zeros((*img.shape[:2], 4), dtype=np.uint8)\n",
    "maskalpha[maskbool, 0:3] = [255, 0, 0]\n",
    "maskalpha[maskbool, 3] = 255\n",
    "maskalpha[~maskbool] = img[~maskbool]\n",
    "alpha = 0.5\n",
    "overlayed = cv2.addWeighted(img, alpha, maskalpha, 1 - alpha, 0)\n",
    "overlayed = cv2.rectangle(overlayed, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 197, 71, 255), 10)\n",
    "Image.fromarray(overlayed).save(tmpdir / \"rendered_overlay_mask.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d reconstruction + multiview visualization thing + scale ambiguity visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworld_obj = T_from_blender(gtinfo[datasetname][\"R\"], gtinfo[datasetname][\"t\"], scale=gtinfo[datasetname][\"scalefactor\"])\n",
    "scale = 1 / gtinfo[datasetname][\"scalefactor\"]\n",
    "T_zup = T_from_blender(gtinfo[datasetname][\"R_floor\"], gtinfo[datasetname][\"t_floor\"], scale=1).inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtposes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densepc_zup = scale_pc(T_zup @ densepc, scale)\n",
    "cams_zup = scale_cams(cams.apply_transform(T_zup), scale)\n",
    "cam1 = cams_zup[0]\n",
    "cam2 = cams_zup[-1]\n",
    "foundposeest1 = list(filter(lambda x: Path(x[\"img_path\"]).stem == imgpaths[0].stem, foundposeests))[1]\n",
    "foundposeT1 = v3d.Transform(R=foundposeest1[\"R\"], t=foundposeest1[\"t\"])\n",
    "T_objworld1 = cam1.world_from_cam @ foundposeT1\n",
    "foundposeest2 = list(filter(lambda x: Path(x[\"img_path\"]).stem == imgpaths[-1].stem, foundposeests))[4]\n",
    "foundposeT2 = v3d.Transform(R=foundposeest2[\"R\"], t=foundposeest2[\"t\"])\n",
    "T_objworld2 = cam2.world_from_cam @ foundposeT2\n",
    "# v3d.make_fig([densepc_zup, cam1, cam2, get_line3d_trace(cams_zup.world_from_cam.t, markersize=3, linewidth=3), T_objworld @ meshpc])\n",
    "_, wiretrace1 = get_trimesh_traces(mesh.copy().apply_transform(T_objworld1.matrix4x4), wirecolor=\"rgba(255, 0, 0, 150)\")\n",
    "_, wiretrace2 = get_trimesh_traces(mesh.copy().apply_transform(T_objworld2.matrix4x4), wirecolor=\"rgba(0, 0, 255, 150)\")\n",
    "fig = v3d.make_fig([densepc_zup, cam1, cam2.make_traces()[0].update(marker={\"color\": \"rgb(0, 0, 255)\"}), get_line3d_trace(cams_zup.world_from_cam.t, markersize=3, linewidth=3), wiretrace1, wiretrace2])\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    ")\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"width\": 1200,\n",
    "        \"height\": 900,\n",
    "        \"filename\": \"multiview3d-2cams\",\n",
    "        # 'scale': 10,\n",
    "    }\n",
    "}\n",
    "fig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "fig.show(config=config)\n",
    "\n",
    "# /scratch/jeyan/barreldata/tmp/newplot.png\n",
    "# /Users/jerry/Projects/ms-stuff/barrel-playground/tmp/newplot.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(imgpaths[0]).convert(\"RGBA\"))\n",
    "objwireframe, _, _ = render_models(cam1, [recolor_mesh(mesh, [255, 0, 0, 255]), recolor_mesh(mesh, [0, 0, 255, 255])], [T_objworld1, T_objworld2], light_intensity=5000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "wireframemask = objwireframe[..., 3] > 0\n",
    "objwireframe[wireframemask, 3] = 255\n",
    "# objwireframe[~wireframemask] = img[~wireframemask]\n",
    "Image.fromarray(overlay_img_alpha(img, objwireframe, alpha=0.5)).save(tmpdir / \"cam1_wireframe.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(imgpaths[-1]).convert(\"RGBA\"))\n",
    "objwireframe, _, _ = render_models(cam2, [recolor_mesh(mesh, [255, 0, 0, 255]), recolor_mesh(mesh, [0, 0, 255, 255])], [T_objworld1, T_objworld2], light_intensity=5000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "wireframemask = objwireframe[..., 3] > 0\n",
    "objwireframe[wireframemask, 3] = 255\n",
    "# objwireframe[~wireframemask] = img[~wireframemask]\n",
    "Image.fromarray(overlay_img_alpha(img, objwireframe, alpha=0.5)).save(tmpdir / \"cam2_wireframe.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densepc_zup_unscaled = T_zup @ densepc\n",
    "cams_zup_unscaled = cams.apply_transform(T_zup)\n",
    "fig = v3d.make_fig([densepc_zup_unscaled, cams_zup_unscaled])\n",
    "plotlycam = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': 0.979302700454209, 'y': -0.8701522198840933, 'z': 0.7050176661837763},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1},\n",
    "}\n",
    "fig.update_layout(\n",
    "    scene_camera=plotlycam,\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    "    # template='none',\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            # showgrid=False,\n",
    "            # zeroline=False,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            # showgrid=False,\n",
    "            # zeroline=False,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            # showgrid=False,\n",
    "            # zeroline=False,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "fig.update_scenes(xaxis_visible=False, yaxis_visible=True, zaxis_visible=False)\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"colmapraw\",\n",
    "        \"width\": None,\n",
    "        \"height\": None,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "fig.write_image(tmpdir / \"colmapraw.png\", scale=1)\n",
    "f = go.FigureWidget(fig)\n",
    "f\n",
    "# fig.show(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layout['scene']['camera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2cams_gt = []\n",
    "for i, gtposeinfo in enumerate(sorted(gtposes, key=lambda x: x[\"img_path\"])):\n",
    "    T = v3d.Transform(R=gtposeinfo[\"R\"], t=gtposeinfo[\"t\"])\n",
    "    obj2cams_gt.append(T)\n",
    "obj2cams_gt = dca.stack(obj2cams_gt)\n",
    "obj2cams_est = []\n",
    "for i, estposeinfo in enumerate(filter(lambda x: x[\"hypothesis_id\"] == \"0\", sorted(ests, key=lambda x: x[\"img_path\"]))):\n",
    "    T = v3d.Transform(R=estposeinfo[\"R\"], t=estposeinfo[\"t\"])\n",
    "    obj2cams_est.append(T)\n",
    "obj2cams_est = dca.stack(obj2cams_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_camfront_unscaledpc = (cams_zup_unscaled.world_from_cam @ obj2cams_est @ meshpc[None, ...])\n",
    "colors = (255 * cmapvals(np.arange(len(cams_zup_unscaled)), cmap=\"tab20\")).astype(np.uint8)\n",
    "traces = []\n",
    "skip = 4\n",
    "for i, cam_zup_unscaled in enumerate(cams_zup_unscaled):\n",
    "    if i % skip != 0:\n",
    "        continue\n",
    "    camtrace = cam_zup_unscaled.make_traces()[0].update(line={\"color\": rgb2hex(colors[i])})\n",
    "    # meshtrace = mesh_camfront_unscaledpc[i].replace(rgb=colors[i])\n",
    "    _, wiretrace = get_trimesh_traces(mesh.copy().apply_transform((cams_zup_unscaled.world_from_cam[i] @ obj2cams_est[i]).matrix4x4), wirecolor=rgb2hex(colors[i]))\n",
    "    traces.append(camtrace)\n",
    "    traces.append(wiretrace)\n",
    "fig = v3d.make_fig([*traces, densepc_zup_unscaled, get_line3d_trace(cams_zup_unscaled.world_from_cam.t, markersize=1, linewidth=2, linecolor=\"#ab63fa\")])\n",
    "plotlycam = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': 1.7135838058633417, 'y': -1.2023497067709676, 'z': 0.5527076287791509},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1},\n",
    "}\n",
    "fig.update_layout(\n",
    "    scene_camera=plotlycam,\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    ")\n",
    "fig.write_image(tmpdir / \"colmap-unscaled.png\", scale=2)\n",
    "f = go.FigureWidget(fig)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layout['scene']['camera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_camfront_pc = (cams_zup.world_from_cam @ obj2cams_est @ meshpc[None, ...])\n",
    "traces = []\n",
    "for i, cam_zup in enumerate(cams_zup):\n",
    "    if i % skip != 0:\n",
    "        continue\n",
    "    camtrace = cam_zup.make_traces()[0].update(line={\"color\": rgb2hex(colors[i])})\n",
    "    # meshtrace = mesh_camfront_pc[i].replace(rgb=colors[i])\n",
    "    _, wiretrace = get_trimesh_traces(mesh.copy().apply_transform((cams_zup.world_from_cam[i] @ obj2cams_est[i]).matrix4x4), wirecolor=rgb2hex(colors[i]))\n",
    "    traces.append(camtrace)\n",
    "    traces.append(wiretrace)\n",
    "fig = v3d.make_fig([*traces, densepc_zup, get_line3d_trace(cams_zup.world_from_cam.t, markersize=3, linewidth=3, linecolor=\"#ab63fa\")])\n",
    "plotlycam = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': 1.7135838058633417, 'y': -1.2023497067709676, 'z': 0.5527076287791509},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1},\n",
    "}\n",
    "fig.update_layout(\n",
    "    scene_camera=plotlycam,\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    ")\n",
    "fig.write_image(tmpdir / \"colmap-scaled.png\", scale=2)\n",
    "f = go.FigureWidget(fig)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layout['scene']['camera']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ICP + rotation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objinfo[\"barrelsingle-scaled.ply\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = cams\n",
    "use_coarse = True\n",
    "scenepts = densepc.replace()\n",
    "masks = []\n",
    "for i, maskinfo in enumerate(masksinfo):\n",
    "    maskpath = Path(maskinfo[\"mask_paths\"][maskinfo[\"best_idx\"]])\n",
    "    maskpath = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results\") / Path(*maskpath.parts[-4:])\n",
    "    masks.append(np.array(Image.open(maskpath).convert(\"L\")))\n",
    "masks = np.array(masks)\n",
    "objectmesh = mesh.copy()\n",
    "objectsymmetries = get_symmetry_transformations(objinfo[\"barrelsingle-scaled.ply\"], 0.01)\n",
    "\n",
    "\n",
    "cams = cameras\n",
    "# names, cameras are already assumed to be ordered and filtered\n",
    "# depending on failed registration in COLMAP or SAM masks\n",
    "name2cam = {name: cam for name, cam in zip(names, cameras)}\n",
    "# foundpose results are used as reference for image ids\n",
    "name2imgid = {}\n",
    "name2imgpath = {}\n",
    "obj2cams: v3d.Transform = []\n",
    "# camera for each hypothesis. If multiple hypotheses for each image, there will be\n",
    "# duplicate cameras in here\n",
    "camhyps: v3d.Camera = []\n",
    "# colmap usually can't reconstruct every camera pose, so we can only fit the\n",
    "# foundpose results with a camera pose\n",
    "for fres in foundposeests:\n",
    "    imgpath = Path(fres[\"img_path\"])\n",
    "    name = imgpath.stem\n",
    "    if name not in name2imgid.keys():\n",
    "        name2imgid[name] = fres[\"img_id\"]\n",
    "    if name not in name2imgpath.keys():\n",
    "        name2imgpath[name] = imgpath\n",
    "    # could just use the \"best\" hypothesis. pretty often though, this hypothesis sucks.\n",
    "    # valid_hyp = name in name2cam.keys() and fres[\"hypothesis_id\"] == \"0\"\n",
    "    valid_hyp = name in names\n",
    "    if valid_hyp:\n",
    "        camhyps.append(name2cam[name])\n",
    "        if use_coarse:\n",
    "            R = fres[\"R_coarse\"]\n",
    "            t = fres[\"t_coarse\"]\n",
    "        else:\n",
    "            R = fres[\"R\"]\n",
    "            t = fres[\"t\"]\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = np.reshape(t, -1)\n",
    "        obj2cams.append(v3d.Transform.from_matrix(T))\n",
    "obj2cams = dca.stack(obj2cams)\n",
    "camhyps = dca.stack(camhyps)\n",
    "\n",
    "model, inlieridxs = ransac(\n",
    "    camhyps.world_from_cam.matrix4x4,\n",
    "    obj2cams.matrix4x4,\n",
    "    fit_func=fitcams,\n",
    "    loss_func=camloss,\n",
    "    cost_func=camcost,\n",
    "    samp_min=5,\n",
    "    inlier_min=5,\n",
    "    inlier_thres=0.15,\n",
    "    max_iter=50,\n",
    "    seed=0,\n",
    "    relax_on_fail=True,\n",
    ")\n",
    "\n",
    "scalefactor = model.scale\n",
    "camscaled = scale_cams(cams, scalefactor)\n",
    "camhypsscaled = scale_cams(camhyps, scalefactor)\n",
    "obj2worlds = camhypsscaled.world_from_cam @ obj2cams\n",
    "obj2worldsinlier: v3d.Transform = obj2worlds[inlieridxs]\n",
    "\n",
    "sceneptsscaled = scenepts.replace(p=scenepts.p * scalefactor)\n",
    "segidxs = segment_pc_from_masks(sceneptsscaled, masks, camscaled, min_ratio=1/2)\n",
    "\n",
    "# plane fit to seafloor\n",
    "floormask = np.ones(len(sceneptsscaled), dtype=bool)\n",
    "floormask[segidxs] = False\n",
    "plane1 = pyrsc.Plane()\n",
    "best_eq, best_inliers = plane1.fit(sceneptsscaled[floormask].p, thresh=0.005)\n",
    "a, b, c, d = best_eq\n",
    "normal = np.array([a, b, c])\n",
    "R = get_axes_rot([0, 0, 1], normal)\n",
    "planecent = [0, 0, -d / c]\n",
    "Tmat = np.eye(4)\n",
    "Tmat[:3, :3] = R\n",
    "Tmat[:3, 3] = planecent\n",
    "planeT = v3d.Transform.from_matrix(Tmat)\n",
    "camzup = camscaled.apply_transform(planeT.inv)\n",
    "if np.mean(camzup.world_from_cam.t[:, 2]) < 0:\n",
    "    planeT = planeT @ v3d.Transform.from_matrix(np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]))\n",
    "    camzup = camscaled.apply_transform(planeT.inv)\n",
    "    normal = -normal\n",
    "\n",
    "# 3x points from sfm point cloud\n",
    "meshsamp, _ = trimesh.sample.sample_surface(objectmesh, count=len(segidxs))\n",
    "objinscenepts = sceneptsscaled[segidxs]\n",
    "# simple outlier removal to see if this works\n",
    "o3dobj = o3d.geometry.PointCloud()\n",
    "o3dobj.points = o3d.utility.Vector3dVector(objinscenepts.p)\n",
    "_, inlieridx = o3dobj.remove_statistical_outlier(nb_neighbors=50, std_ratio=2.0)\n",
    "tmpT = []\n",
    "for i, obj2world in enumerate(obj2worldsinlier):\n",
    "    samp_trf = obj2world @ meshsamp\n",
    "    # source is sfm point cloud, since it is incomplete\n",
    "    icpT = v3d.Transform.from_matrix(icp(objinscenepts.p[inlieridx], samp_trf, outlier_std=2.0))\n",
    "    tmpT.append(icpT.inv @ obj2world)\n",
    "    # debug figure (this takes a while to generate)\n",
    "    meshpts = planeT.inv @ v3d.Point3d(p=samp_trf, rgb=[0, 0, 255])\n",
    "    meshicppts = planeT.inv @ v3d.Point3d(p=icpT.inv @ samp_trf, rgb=[0, 255, 0])\n",
    "    sceneobjzuppts = planeT.inv @ objinscenepts[inlieridx]\n",
    "    sceneobjzupoutlierpts = planeT.inv @ objinscenepts[invert_idxs(inlieridx, len(objinscenepts))]\n",
    "    sceneobjzupoutlierpts = sceneobjzupoutlierpts.replace(rgb=[255, 0, 0])\n",
    "    xycent = np.mean(sceneobjzuppts.p, axis=0)[:2]\n",
    "    centT = T_from_translation(-xycent[0], -xycent[1], 0)\n",
    "    icpfig = v3d.make_fig(\n",
    "        [centT @ meshpts, centT @ meshicppts, centT @ sceneobjzuppts, centT @ sceneobjzupoutlierpts],\n",
    "    num_samples_point3d=1000)\n",
    "    # icpfig.write_image(icpdebugdir / f\"icpout_{str(i).zfill(4)}.png\")\n",
    "obj2worldsinlier = dca.stack(tmpT)\n",
    "\n",
    "quatsinlier = quaternion.from_rotation_matrix(obj2worldsinlier.R)\n",
    "ref = quatsinlier[0]\n",
    "quatssymd = [ref]\n",
    "for otherquat in quatsinlier[1:]:\n",
    "    best = closest_quat_sym(ref, otherquat, objectsymmetries)\n",
    "    quatssymd.append(best)\n",
    "quatssymd = np.array(quatssymd)\n",
    "obj2worldsinliersym = obj2worldsinlier.replace(R=quaternion.as_rotation_matrix(quatssymd))\n",
    "\n",
    "qmeanransac, qinliers = ransac(quatssymd, fit_func=qmean, loss_func=qloss, cost_func=qcost, samp_min=5, inlier_min=5, inlier_thres=0.2, max_iter=50, relax_on_fail=True)\n",
    "\n",
    "meanT = v3d.Transform(R=quaternion.as_rotation_matrix(qmeanransac), t=np.mean(obj2worldsinliersym.t, axis=0))\n",
    "quatfig = v3d.make_fig(*get_axes_traces(obj2worldsinliersym, scale=0.5), *get_axes_traces(meanT, linewidth=10))\n",
    "\n",
    "# burial ratio by fitting plane to floor point cloud\n",
    "T_zup = planeT.inv @ meanT\n",
    "meshzup = objectmesh.copy().apply_transform(T_zup.matrix4x4)\n",
    "mesh_zvals = meshzup.vertices[:, 2]\n",
    "zmin, zmax = np.min(mesh_zvals), np.max(mesh_zvals)\n",
    "if zmin >= 0:\n",
    "    burial_ratio_z = 0\n",
    "else:\n",
    "    burial_ratio_z = abs(zmin) / (abs(zmin) + zmax)\n",
    "slicedmesh = trimesh.intersections.slice_mesh_plane(meshzup, [0, 0, 1], [0, 0, 0], cap=True)\n",
    "burial_ratio_vol = 1 - slicedmesh.volume / objectmesh.volume\n",
    "burial_depth = abs(zmin)\n",
    "\n",
    "# visualization of fitted scene\n",
    "meshzuppts = v3d.Point3d(p=meshzup.vertices)\n",
    "scenezuppts = planeT.inv @ sceneptsscaled\n",
    "aggfig = v3d.make_fig([scenezuppts, meshzuppts, camzup])\n",
    "\n",
    "plane2camfit = camscaled.world_from_cam.inv @ planeT[..., None]\n",
    "obj2camfit = camscaled.world_from_cam.inv @ meanT[..., None]\n",
    "estposes = []\n",
    "for name, obj2cam, plane2cam in zip(names, obj2camfit, plane2camfit):\n",
    "    posedata = {\n",
    "        \"img_path\": str(name2imgpath[name]),\n",
    "        \"img_id\": name2imgid[name],\n",
    "        \"hypothesis_id\": \"0\",\n",
    "        \"R\": obj2cam.R.tolist(),\n",
    "        \"t\": obj2cam.t.tolist(),\n",
    "        \"R_floor\": plane2cam.R.tolist(),\n",
    "        \"t_floor\": plane2cam.t.tolist(),\n",
    "    }\n",
    "    estposes.append(posedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2world = obj2worldsinlier[2]\n",
    "# samp_trf = obj2world @ meshpc\n",
    "# meshpts = centT @ planeT.inv @ samp_trf.replace(rgb=[0, 0, 255])\n",
    "# undo ICP transform\n",
    "_, wireframetrace = get_trimesh_traces(mesh.copy().apply_transform((centT @ planeT.inv @ icpT @ obj2world).matrix4x4), wirecolor=\"rgb(0, 0, 255)\")\n",
    "# meshicppts = centT @ planeT.inv @ (icpT.inv @ samp_trf).replace(rgb=[0, 255, 0])\n",
    "_, wireframeicptrace = get_trimesh_traces(mesh.copy().apply_transform((centT @ planeT.inv @ obj2world).matrix4x4), wirecolor=\"rgb(0, 255, 0)\")\n",
    "# sceneobjzuppts = planeT.inv @ objinscenepts[inlieridx]\n",
    "sceneobjzuppts = planeT.inv @ objinscenepts\n",
    "# sceneobjzupoutlierpts = planeT.inv @ objinscenepts[invert_idxs(inlieridx, len(objinscenepts))]\n",
    "# sceneobjzupoutlierpts = centT @ sceneobjzupoutlierpts.replace(rgb=[181, 103, 0])\n",
    "sceneobjzuppts = centT @ sceneobjzuppts.replace(rgb=[212, 130, 23])\n",
    "xycent = np.mean(sceneobjzuppts.p, axis=0)[:2]\n",
    "centT = T_from_translation(-xycent[0], -xycent[1], 0)\n",
    "floorpts = centT @ planeT.inv @ sceneptsscaled[invert_idxs(segidxs, len(sceneptsscaled))]\n",
    "floorpts = floorpts.replace(rgb=[255, 200, 200])\n",
    "icpfig = v3d.make_fig(\n",
    "    [wireframetrace, wireframeicptrace, sceneobjzuppts, sceneobjzupoutlierpts, floorpts],\n",
    "num_samples_point3d=1000)\n",
    "icpfig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"icpvis\",\n",
    "        \"width\": None,\n",
    "        \"height\": None,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "icpfig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "icpfig.show(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faintpc = centT @ planeT.inv @ sceneptsscaled\n",
    "faintpc = faintpc.replace(rgb=[255, 200, 200])[::50]\n",
    "trace = faintpc.make_traces()[0].update(marker={\"color\": \"rgba(255, 10, 10, 0.3)\", \"size\": 2})\n",
    "newquatfig = v3d.make_fig(*get_axes_traces(centT @ planeT.inv @ obj2worldsinliersym, scale=0.5), *get_axes_traces(centT @ planeT.inv @ meanT, linewidth=10), trace)\n",
    "# newquatfig = v3d.make_fig(*get_axes_traces(centT @ planeT.inv @ obj2worldsinliersym, scale=0.5), trace)\n",
    "newquatfig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"quatavgvis\",\n",
    "        \"width\": 1500,\n",
    "        \"height\": 750,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "newquatfig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "newquatfig.show(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sceneobjzuppts = planeT.inv @ objinscenepts[inlieridx]\n",
    "sceneobjzuppts = sceneobjzuppts.replace(rgb=[255, 0, 0])\n",
    "xycent = np.mean(sceneobjzuppts.p, axis=0)[:2]\n",
    "centT = T_from_translation(-xycent[0], -xycent[1], 0)\n",
    "crap = centT @ planeT.inv @ sceneptsscaled[invert_idxs(segidxs, len(sceneptsscaled))]\n",
    "crap = crap.replace(rgb=[255, 0, 0])\n",
    "shit = centT @ planeT.inv @ sceneptsscaled[segidxs]\n",
    "shit = shit.replace(rgb=[255, 200, 200])\n",
    "xx, yy, zz = get_plane_zup(crap.p, n=10, z=0, square_grid=True)\n",
    "planetrace = go.Surface(x=xx, y=yy, z=zz, opacity=0.5, colorscale=\"purples\")\n",
    "planeoutlinetrace = get_surface_line_traces(xx, yy, zz)\n",
    "zupray = get_ray_trace([0, 1, 0], [0, 0, 1], length=1.5, width=5, color=\"#10c900\")\n",
    "trfmesh = mesh.copy().apply_transform((centT @ planeT.inv @ obj2world).matrix4x4)\n",
    "facecols = [\"#c98000\"] * len(trfmesh.faces)\n",
    "meshfig = ff.create_trisurf(x=trfmesh.vertices[:, 0], y=trfmesh.vertices[:, 1], z=trfmesh.vertices[:, 2], simplices=trfmesh.faces, color_func=facecols, show_colorbar=False)\n",
    "planefitfig = v3d.make_fig(\n",
    "    [crap, shit.make_traces()[0].update(marker={\"color\": \"rgba(200, 1, 1, 0.005)\"}), planetrace, *planeoutlinetrace, zupray, *meshfig.select_traces()],\n",
    "num_samples_point3d=1000)\n",
    "planefitfig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "# 1200/450\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"planefitvis\",\n",
    "        \"width\": 2400,\n",
    "        \"height\": 900,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "planefitfig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "planefitfig.show(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map of burial fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiview_fitted = True\n",
    "pose_type = \"refined\"\n",
    "use_icp = True\n",
    "metricsfiltdf = metricsdf[(metricsdf[\"multiview_fitted\"] == multiview_fitted) & (metricsdf[\"pose_type\"] == pose_type) & (metricsdf[\"use_icp\"] == use_icp)]\n",
    "burialdepths = metricsfiltdf[\"burial_depth\"].values\n",
    "burialdepths_gt = metricsfiltdf[\"burial_depth_gt\"].values\n",
    "burialdepths_err = metricsfiltdf[\"burial_error_depth\"].values\n",
    "lats = metricsfiltdf[\"lat\"].values\n",
    "lons = metricsfiltdf[\"lon\"].values\n",
    "\n",
    "def within_domain(lats, lons, domain):\n",
    "    latmin, latmax = domain[\"S\"], domain[\"N\"]\n",
    "    lonmin, lonmax = domain[\"W\"], domain[\"E\"]\n",
    "    return (latmin <= lats) & (lats <= latmax) & (lonmin <= lons) & (lons <= lonmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### newer figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pcolor plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering, MeanShift, AgglomerativeClustering\n",
    "\n",
    "positions = np.array([lons, lats]).T\n",
    "# clustermodel = KMeans(n_clusters=5, random_state=0).fit(positions)\n",
    "# clustermodel = SpectralClustering(n_clusters=5, random_state=0).fit(positions)\n",
    "# clustermodel = MeanShift(bandwidth=10).fit(positions)\n",
    "clustermodel = AgglomerativeClustering(n_clusters=None, distance_threshold=0.007).fit(positions)\n",
    "posclass = clustermodel.labels_\n",
    "plt.scatter(lons, lats, c=posclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = generate_domain(lats, lons, padding=0.01)\n",
    "xi = np.linspace(domain[\"W\"], domain[\"E\"], 500)\n",
    "yi = np.linspace(domain[\"S\"], domain[\"N\"], 500)\n",
    "grid = np.meshgrid(xi, yi)\n",
    "fig, ax = get_carree_axis(domain=domain, land=True)\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=\"#dbf7ff\")\n",
    "get_carree_gl(ax)\n",
    "for i in range(clustermodel.n_clusters_):\n",
    "    mask = posclass == i\n",
    "    if np.sum(mask) <= 2:\n",
    "        continue\n",
    "    zi = scipy.interpolate.griddata(np.array([lons, lats]).T[mask], burialdepths_gt[mask], grid, method=\"linear\")\n",
    "    pcmesh = ax.pcolormesh(xi, yi, zi)\n",
    "# pcmesh = ax.pcolormesh(xi, yi, zi)\n",
    "# sc = ax.scatter(lons, lats, color=\"red\", edgecolor=\"k\", s=4)\n",
    "cb = plt.colorbar(pcmesh, label=\"Burial Depths (m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain = generate_domain(lats, lons, padding=0.3)\n",
    "domain = {\n",
    "    \"W\": -118.6,\n",
    "    \"E\": -118.2,\n",
    "    \"S\": 33.33,\n",
    "    \"N\": 33.62,\n",
    "}\n",
    "# insetdomain = generate_domain(lats, lons, padding=0.01)\n",
    "insetdomain = {\n",
    "    \"W\": -118.445,\n",
    "    \"E\": -118.415,\n",
    "    \"S\": 33.559,\n",
    "    \"N\": 33.568,\n",
    "}\n",
    "vmin = min(np.min(burialdepths_gt), np.min(burialdepths))\n",
    "vmax = max(np.max(burialdepths_gt), np.max(burialdepths))\n",
    "xi = np.linspace(domain[\"W\"], domain[\"E\"], 1000)\n",
    "yi = np.linspace(domain[\"S\"], domain[\"N\"], 1000)\n",
    "grid = np.meshgrid(xi, yi)\n",
    "zi = scipy.interpolate.griddata(np.array([lons, lats]).T, burialdepths_gt, grid, method=\"linear\")\n",
    "fig, ax = get_carree_axis(domain=domain, land=True)\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=\"#dbf7ff\")\n",
    "get_carree_gl(ax)\n",
    "for i in range(clustermodel.n_clusters_):\n",
    "    mask = posclass == i\n",
    "    if np.sum(mask) < 2:\n",
    "        continue\n",
    "    zi = scipy.interpolate.griddata(np.array([lons, lats]).T[mask], burialdepths_gt[mask], grid, method=\"linear\")\n",
    "    pcmesh = ax.pcolormesh(xi, yi, zi, vmin=vmin, vmax=vmax)\n",
    "cb = plt.colorbar(pcmesh, label=\"Burial Depth (m)\")\n",
    "sc = ax.scatter(lons, lats, color=\"red\", edgecolor=\"k\", s=5, alpha=0.7)\n",
    "axins = ax.inset_axes(\n",
    "    [0.1, 0.05, 0.87, 0.68],\n",
    "    xlim=(insetdomain[\"W\"], insetdomain[\"E\"]),\n",
    "    ylim=(insetdomain[\"S\"], insetdomain[\"N\"]),\n",
    "    xticklabels=[], yticklabels=[]\n",
    ")\n",
    "xi = np.linspace(insetdomain[\"W\"], insetdomain[\"E\"], 100)\n",
    "yi = np.linspace(insetdomain[\"S\"], insetdomain[\"N\"], 100)\n",
    "grid = np.meshgrid(xi, yi)\n",
    "for i in range(clustermodel.n_clusters_):\n",
    "    mask = posclass == i\n",
    "    if np.sum(mask) <= 2:\n",
    "        continue\n",
    "    zi = scipy.interpolate.griddata(np.array([lons, lats]).T[mask], burialdepths_gt[mask], grid, method=\"linear\")\n",
    "    pcmesh = axins.pcolormesh(xi, yi, zi, vmin=vmin, vmax=vmax, edgecolors=\"face\")\n",
    "axins.scatter(lons, lats, color=\"red\", edgecolor=\"k\", s=3, alpha=0.7)\n",
    "axins.set_facecolor(\"#dbf7ff\")\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "fig.suptitle(\"Absolute burial depth GT\")\n",
    "# fig.savefig(tmpdir / \"burialmapgt_pcolor.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"plasma\"\n",
    "# domain = generate_domain(lats, lons, padding=0.3)\n",
    "domain = {\n",
    "    \"W\": -118.6,\n",
    "    \"E\": -118.2,\n",
    "    \"S\": 33.42,\n",
    "    \"N\": 33.62,\n",
    "}\n",
    "# insetdomain = generate_domain(lats, lons, padding=0.01)\n",
    "insetdomain = {\n",
    "    \"W\": -118.445,\n",
    "    \"E\": -118.415,\n",
    "    \"S\": 33.559,\n",
    "    \"N\": 33.568,\n",
    "}\n",
    "vmin = min(np.min(burialdepths_gt), np.min(burialdepths))\n",
    "vmax = max(np.max(burialdepths_gt), np.max(burialdepths))\n",
    "fig, ax = get_carree_axis(domain=domain, land=True)\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=\"#dbf7ff\")\n",
    "get_carree_gl(ax)\n",
    "sc = ax.scatter(lons, lats, c=burialdepths_gt, s=3, alpha=0.8, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "axins = ax.inset_axes(\n",
    "    [0.1, 0.0, 0.87, 0.68],\n",
    "    projection=ccrs.PlateCarree(),\n",
    "    xlim=(insetdomain[\"W\"], insetdomain[\"E\"]),\n",
    "    ylim=(insetdomain[\"S\"], insetdomain[\"N\"]),\n",
    "    xticklabels=[], yticklabels=[]\n",
    ")\n",
    "get_carree_gl(axins, labels=False)\n",
    "scin = axins.scatter(lons, lats, c=burialdepths_gt, s=5, alpha=0.8, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "cb = plt.colorbar(sc, ax=ax, label=\"Burial Depth (m)\", fraction=0.025, pad=0.04)\n",
    "axins.set_facecolor(\"#dbf7ff\")\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "# fig.suptitle(\"Absolute burial depth GT\")\n",
    "fig.savefig(tmpdir / \"burialmapgt.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.savefig(tmpdir / \"burialmapgt.png\", dpi=300, bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = get_carree_axis(domain=insetdomain, land=True)\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=\"#dbf7ff\")\n",
    "get_carree_gl(ax)\n",
    "sc = ax.scatter(lons, lats, c=burialdepths, s=5, alpha=0.8, vmin=vmin, vmax=vmax, cmap=cmap)\n",
    "cb = plt.colorbar(scin, ax=ax, label=\"Burial Depth (m)\", fraction=0.025, pad=0.04)\n",
    "# fig.suptitle(\"Absolute burial depth predicted\")\n",
    "fig.savefig(tmpdir / \"burialmappred.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errmin = np.min(burialdepths_err)\n",
    "errmax = np.max(burialdepths_err)\n",
    "fig, ax = get_carree_axis(domain=insetdomain, land=True)\n",
    "ax.add_feature(cartopy.feature.OCEAN, facecolor=\"#dbf7ff\")\n",
    "get_carree_gl(ax)\n",
    "sc = ax.scatter(lons, lats, c=burialdepths_err, s=5, alpha=0.8, vmin=errmin, vmax=errmax, cmap=cmap)\n",
    "cb = plt.colorbar(scin, ax=ax, label=\"Absolute Burial Depth Error (m)\", fraction=0.025, pad=0.04)\n",
    "# fig.suptitle(\"Absolute burial depth predicted\")\n",
    "fig.savefig(tmpdir / \"burialmaperr.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookhere = filtermetrics(metricsdf, name=\"dive3-depthcharge-05-11\", multiview_fitted=True, use_icp=True, pose_type=\"coarse\").iloc[0]\n",
    "# lookhere = filtermetrics(metricsdf, name=\"barrel2\", multiview_fitted=True, use_icp=True, pose_type=\"coarse\").iloc[0]\n",
    "# lookhere = filtermetrics(metricsdf, name=\"dive6-smokefloat-10-17-26\", multiview_fitted=True, use_icp=True, pose_type=\"coarse\").iloc[0]\n",
    "trace = go.Scatter(\n",
    "    x=lons,\n",
    "    y=lats,\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "    ),\n",
    ")\n",
    "tracesingle = go.Scatter(\n",
    "    x=[lookhere[\"lon\"]],\n",
    "    y=[lookhere[\"lat\"]],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "    ),\n",
    ")\n",
    "go.Figure(data=[trace, tracesingle]).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barrels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
