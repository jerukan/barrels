{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures galore\n",
    "\n",
    "results visualizations for paper or something idk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup, data loading needed for most visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import dataclass_array as dca\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import mitsuba as mi\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pycolmap\n",
    "import pyransac3d as pyrsc\n",
    "import pyrender\n",
    "import quaternion\n",
    "import trimesh\n",
    "import visu3d as v3d\n",
    "import yaml\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"bop_toolkit\")))\n",
    "from bop_toolkit.bop_toolkit_lib.pose_error import vsd, mssd, mspd\n",
    "from bop_toolkit.bop_toolkit_lib.misc import get_symmetry_transformations\n",
    "from bop_toolkit.bop_toolkit_lib.renderer import create_renderer\n",
    "\n",
    "import burybarrel.colmap_util as cutil\n",
    "from burybarrel.image import render_v3d, render_models, to_contour, overlay_img_alpha\n",
    "from burybarrel.camera import RadialCamera, load_v3dcams\n",
    "from burybarrel.mesh import subdivide_mesh, recolor_mesh, segment_pc_from_masks\n",
    "from burybarrel.transform import T_from_blender, T_from_translation, scale_T_translation, scale_cams, scale_pc, icp, qangle, qmean, closest_quat_sym, get_axes_rot\n",
    "from burybarrel.plotting import get_line3d_trace, get_axes_traces\n",
    "from burybarrel.utils import rgb2hex, cmapvals, match_lists, invert_idxs\n",
    "from burybarrel.estimators import ransac\n",
    "from burybarrel.foundpose_fit import fitcams, camloss, camcost, qcost, qloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmpdir = Path(\"/scratch/jeyan/barreldata/tmp\")\n",
    "tmpdir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/tmp\")\n",
    "# metricscsvpath = Path(\"/scratch/jeyan/barreldata/results/allmetrics.csv\")\n",
    "metricscsvpath = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results/allmetrics.csv\")\n",
    "metricsdf = pd.read_csv(metricscsvpath)\n",
    "metricsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsdf[[\"avg_vsd\", \"avg_mssd\", \"avg_mspd\", \"multiview_fitted\", \"pose_type\", \"use_icp\"]].groupby([\"multiview_fitted\", \"pose_type\", \"use_icp\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading EVERYTHING\n",
    "datasetname = \"barrelddt1\"\n",
    "singledatarows = metricsdf[metricsdf[\"dataset\"] == datasetname]\n",
    "\n",
    "resrow = singledatarows.iloc[3]\n",
    "datadir = Path(resrow[\"datadir\"])\n",
    "datadir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/data/input_data\") / datadir.name\n",
    "resdir = Path(resrow[\"resdir\"])\n",
    "resdir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results\") / Path(*resdir.parts[-3:])\n",
    "object_name = resrow[\"object_name\"]\n",
    "\n",
    "with open(\"../configs/blender_gt_info.yaml\", \"rt\") as f:\n",
    "    gtinfo = yaml.safe_load(f)\n",
    "with open(datadir / \"gt_obj2cam.json\", \"rt\") as f:\n",
    "    gtposes = yaml.safe_load(f)\n",
    "with open(datadir / \"info.json\", \"rt\") as f:\n",
    "    datainfo = yaml.safe_load(f)\n",
    "with open(datadir / \"camera.json\", \"rt\") as f:\n",
    "    caminfo = yaml.safe_load(f)\n",
    "with open(resdir / \"../../sam-masks/masksinfo.json\", \"rt\") as f:\n",
    "    masksinfo = yaml.safe_load(f)\n",
    "posepath = resdir / \"estimated-poses.json\"\n",
    "estinfopath = resdir / \"reconstruction-info.json\"\n",
    "with open(posepath, \"rt\") as f:\n",
    "    ests = yaml.safe_load(f)\n",
    "with open(estinfopath, \"rt\") as f:\n",
    "    estinfo = yaml.safe_load(f)\n",
    "with open(resdir / \"../../foundpose-output/inference/estimated-poses.json\", \"rt\") as f:\n",
    "    foundposeests = yaml.safe_load(f)\n",
    "cams, imgpaths = load_v3dcams(resdir / \"../../colmap-out/cam_poses.json\", img_parent=datadir / \"rgb\")\n",
    "names = [imgpath.stem for imgpath in imgpaths]\n",
    "\n",
    "densepath = resdir / \"../../openmvs-out/scene_dense_trimeshvalid.ply\"\n",
    "densetrimesh: trimesh.PointCloud = trimesh.load_mesh(densepath)\n",
    "densepc = v3d.Point3d(p=densetrimesh.vertices, rgb=densetrimesh.colors[:, :3])\n",
    "\n",
    "camspec = RadialCamera.from_jsonargs(**caminfo)\n",
    "# objdir = Path(\"/scratch/jeyan/barreldata/models3d\")\n",
    "objdir = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/models3d\")\n",
    "objpath = objdir / object_name\n",
    "with open(objdir / \"model_info.json\", \"rt\") as f:\n",
    "    objinfo = yaml.safe_load(f)\n",
    "mesh: trimesh.Trimesh = trimesh.load_mesh(objpath)\n",
    "meshpc = v3d.Point3d(p=mesh.vertices, rgb=[255, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some 3d overlay wireframe visualization thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5\n",
    "est = ests[idx]\n",
    "gt = gtposes[idx]\n",
    "est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshcol = np.array([255, 0, 0, 255], dtype=np.uint8)\n",
    "planecol = np.array([0, 0, 255, 255], dtype=np.uint8)\n",
    "black = np.array([0, 0, 0, 255], dtype=np.uint8)\n",
    "transparent = np.array([0, 0, 0, 0], dtype=np.uint8)\n",
    "mesh = recolor_mesh(mesh, meshcol)\n",
    "plane = trimesh.creation.box(extents=(100, 100, 0.01))\n",
    "plane = subdivide_mesh(plane, 7)\n",
    "plane = recolor_mesh(plane, planecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2cam = v3d.Transform(R=est[\"R\"], t=est[\"t\"])\n",
    "floor2cam = v3d.Transform(R=est[\"R_floor\"], t=est[\"t_floor\"])\n",
    "obj2camgt = v3d.Transform(R=gt[\"R\"], t=gt[\"t\"])\n",
    "floor2camgt = v3d.Transform(R=gt[\"R_floor\"], t=gt[\"t_floor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = v3d.Camera(spec=camspec, world_from_cam=v3d.Transform.identity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskrgb, _, _ = render_models(cam, [mesh, plane], [obj2cam, floor2cam], light_intensity=1000, flags=pyrender.RenderFlags.FLAT)\n",
    "objmask = np.all(maskrgb == [255, 0, 0], axis=-1)\n",
    "rgb_wireframe, _, _ = render_models(cam, [recolor_mesh(plane, black)], [floor2cam], light_intensity=1000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "rgb_wireframe = rgb_wireframe * ~objmask[..., None]\n",
    "rgb_primoverlay, _, _ = render_models(cam, [mesh, plane], [obj2cam, floor2cam], light_intensity=50, wireframe=False)\n",
    "Image.fromarray(rgb_wireframe).save(tmpdir / \"rendered_wireframe.png\")\n",
    "Image.fromarray(rgb_primoverlay).save(tmpdir / \"rendered.png\")\n",
    "# img = cv2.cvtColor(cv2.imread(est[\"img_path\"]), cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(cv2.imread(str(datadir / Path(*Path(est[\"img_path\"]).parts[-2:]))), cv2.COLOR_BGR2RGB)\n",
    "alpha = 0.7\n",
    "img = cv2.addWeighted(img, alpha, rgb_primoverlay, 1 - alpha, 0)\n",
    "# wireframewhere = np.where(rgb_wireframe[..., 3] > 0)\n",
    "# img[wireframewhere] = rgb_wireframe[wireframewhere][..., :3]\n",
    "img = overlay_img_alpha(img, rgb_wireframe)\n",
    "mesh_wireframe, _, _ = render_models(cam, [recolor_mesh(mesh, black)], [obj2cam], light_intensity=1000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "img = overlay_img_alpha(img, mesh_wireframe, alpha=0.2)\n",
    "Image.fromarray(img).save(tmpdir / \"rendered_overlay.png\")\n",
    "\n",
    "# rgb, _, _ = render_models(cam, [mesh, plane], [obj2camgt, floor2camgt], light_intensity=1000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "# Image.fromarray(rgb).save(tmpdir / \"rendered_gt.png\")\n",
    "# img = cv2.cvtColor(cv2.imread(est[\"img_path\"]), cv2.COLOR_BGR2RGB)\n",
    "# wireframewhere = np.where(rgb[..., 3] > 0)\n",
    "# img[wireframewhere] = rgb[wireframewhere][..., :3]\n",
    "# Image.fromarray(img).save(tmpdir / \"rendered_overlay_gt.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualizing mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "singlemasksinfo = masksinfo[idx]\n",
    "singlemasksinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestidx = singlemasksinfo[\"best_idx\"]\n",
    "# [x_min, y_min, x_max, y_max]\n",
    "bbox = list(map(int, singlemasksinfo[\"bboxes\"][bestidx]))\n",
    "mask = np.array(Image.open(singlemasksinfo[\"mask_paths\"][bestidx]).convert(\"L\"))\n",
    "maskbool = mask > 0\n",
    "img = np.array(Image.open(singlemasksinfo[\"img_path\"]).convert(\"RGBA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskalpha = np.zeros((*img.shape[:2], 4), dtype=np.uint8)\n",
    "maskalpha[maskbool, 0:3] = [255, 0, 0]\n",
    "maskalpha[maskbool, 3] = 255\n",
    "maskalpha[~maskbool] = img[~maskbool]\n",
    "alpha = 0.5\n",
    "overlayed = cv2.addWeighted(img, alpha, maskalpha, 1 - alpha, 0)\n",
    "overlayed = cv2.rectangle(overlayed, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 197, 71, 255), 10)\n",
    "Image.fromarray(overlayed).save(tmpdir / \"rendered_overlay_mask.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d reconstruction + multiview visualization thing + scale ambiguity visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworld_obj = T_from_blender(gtinfo[datasetname][\"R\"], gtinfo[datasetname][\"t\"], scale=gtinfo[datasetname][\"scalefactor\"])\n",
    "scale = 1 / gtinfo[datasetname][\"scalefactor\"]\n",
    "T_zup = T_from_blender(gtinfo[datasetname][\"R_floor\"], gtinfo[datasetname][\"t_floor\"], scale=1).inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtposes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densepc_zup = scale_pc(T_zup @ densepc, scale)\n",
    "cams_zup = scale_cams(cams.apply_transform(T_zup), scale)\n",
    "cam1 = cams_zup[0]\n",
    "cam2 = cams_zup[-1]\n",
    "foundposeest1 = list(filter(lambda x: Path(x[\"img_path\"]).stem == imgpaths[0].stem, foundposeests))[1]\n",
    "foundposeT1 = v3d.Transform(R=foundposeest1[\"R\"], t=foundposeest1[\"t\"])\n",
    "T_objworld = cam1.world_from_cam @ foundposeT1\n",
    "# v3d.make_fig([densepc_zup, cam1, cam2, get_line3d_trace(cams_zup.world_from_cam.t, markersize=3, linewidth=3), T_objworld @ meshpc])\n",
    "fig = v3d.make_fig([densepc_zup, cam1, cam2, get_line3d_trace(cams_zup.world_from_cam.t, markersize=3, linewidth=3)])\n",
    "fig.update_layout(\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    ")\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"width\": 1200,\n",
    "        \"height\": 900,\n",
    "        # 'scale': 10,\n",
    "    }\n",
    "}\n",
    "fig.show(config=config)\n",
    "\n",
    "# /scratch/jeyan/barreldata/tmp/newplot.png\n",
    "# /Users/jerry/Projects/ms-stuff/barrel-playground/tmp/newplot.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(tmpdir / \"newplot.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(imgpaths[0]).convert(\"RGBA\"))\n",
    "objwireframe, _, _ = render_models(cam1, [recolor_mesh(mesh, [255, 0, 0, 255])], [T_objworld], light_intensity=5000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "wireframemask = objwireframe[..., 3] > 0\n",
    "objwireframe[wireframemask, 3] = 255\n",
    "objwireframe[~wireframemask] = img[~wireframemask]\n",
    "Image.fromarray(objwireframe).save(tmpdir / \"cam1_wireframe.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(Image.open(imgpaths[-1]).convert(\"RGBA\"))\n",
    "objwireframe, _, _ = render_models(cam2, [recolor_mesh(mesh, [255, 0, 0, 255])], [T_objworld], light_intensity=5000, wireframe=True, flags=pyrender.RenderFlags.RGBA)\n",
    "wireframemask = objwireframe[..., 3] > 0\n",
    "objwireframe[wireframemask, 3] = 255\n",
    "objwireframe[~wireframemask] = img[~wireframemask]\n",
    "Image.fromarray(objwireframe).save(tmpdir / \"cam2_wireframe.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densepc_zup_unscaled = T_zup @ densepc\n",
    "cams_zup_unscaled = cams.apply_transform(T_zup)\n",
    "fig = v3d.make_fig([densepc_zup_unscaled, cams_zup_unscaled])\n",
    "plotlycam = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': 0.979302700454209, 'y': -0.8701522198840933, 'z': 0.7050176661837763},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1},\n",
    "}\n",
    "fig.update_layout(\n",
    "    scene_camera=plotlycam,\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    "    # template='none',\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            # showgrid=False,\n",
    "            # zeroline=False,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            # showgrid=False,\n",
    "            # zeroline=False,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            # showgrid=False,\n",
    "            # zeroline=False,\n",
    "            showticklabels=False\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "fig.update_scenes(xaxis_visible=False, yaxis_visible=True, zaxis_visible=False)\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"colmapraw\",\n",
    "        \"width\": None,\n",
    "        \"height\": None,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "fig.write_image(tmpdir / \"colmapraw.png\", scale=1)\n",
    "f = go.FigureWidget(fig)\n",
    "f\n",
    "# fig.show(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layout['scene']['camera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2cams_gt = []\n",
    "for i, gtposeinfo in enumerate(sorted(gtposes, key=lambda x: x[\"img_path\"])):\n",
    "    T = v3d.Transform(R=gtposeinfo[\"R\"], t=gtposeinfo[\"t\"])\n",
    "    obj2cams_gt.append(T)\n",
    "obj2cams_gt = dca.stack(obj2cams_gt)\n",
    "obj2cams_est = []\n",
    "for i, estposeinfo in enumerate(filter(lambda x: x[\"hypothesis_id\"] == \"0\", sorted(ests, key=lambda x: x[\"img_path\"]))):\n",
    "    T = v3d.Transform(R=estposeinfo[\"R\"], t=estposeinfo[\"t\"])\n",
    "    obj2cams_est.append(T)\n",
    "obj2cams_est = dca.stack(obj2cams_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cams_zup_unscaled.make_traces()[0].update(line={\"color\": [\"blue\"] * 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 255, size=(len(cams_zup_unscaled), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_camfront_unscaledpc = (cams_zup_unscaled.world_from_cam @ obj2cams_est @ meshpc[None, ...])\n",
    "colors = (255 * cmapvals(np.arange(len(cams_zup_unscaled)), cmap=\"hsv\")).astype(np.uint8)\n",
    "traces = []\n",
    "for i, cam_zup_unscaled in enumerate(cams_zup_unscaled):\n",
    "    camtrace = cam_zup_unscaled.make_traces()[0].update(line={\"color\": rgb2hex(colors[i])})\n",
    "    meshtrace = mesh_camfront_unscaledpc[i].replace(rgb=colors[i])\n",
    "    traces.append(camtrace)\n",
    "    traces.append(meshtrace)\n",
    "fig = v3d.make_fig([*traces, densepc_zup_unscaled])\n",
    "plotlycam = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': 1.7135838058633417, 'y': -1.2023497067709676, 'z': 0.5527076287791509},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1},\n",
    "}\n",
    "fig.update_layout(\n",
    "    scene_camera=plotlycam,\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    ")\n",
    "fig.write_image(tmpdir / \"colmap-unscaled.png\", scale=2)\n",
    "f = go.FigureWidget(fig)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layout['scene']['camera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_camfront_pc = (cams_zup.world_from_cam @ obj2cams_est @ meshpc[None, ...])\n",
    "traces = []\n",
    "for i, cam_zup in enumerate(cams_zup):\n",
    "    camtrace = cam_zup.make_traces()[0].update(line={\"color\": rgb2hex(colors[i])})\n",
    "    meshtrace = mesh_camfront_pc[i].replace(rgb=colors[i])\n",
    "    traces.append(camtrace)\n",
    "    traces.append(meshtrace)\n",
    "fig = v3d.make_fig([*traces, densepc_zup])\n",
    "plotlycam = {\n",
    "    'center': {'x': 0, 'y': 0, 'z': 0},\n",
    "    'eye': {'x': 1.7135838058633417, 'y': -1.2023497067709676, 'z': 0.5527076287791509},\n",
    "    'projection': {'type': 'perspective'},\n",
    "    'up': {'x': 0, 'y': 0, 'z': 1},\n",
    "}\n",
    "fig.update_layout(\n",
    "    scene_camera=plotlycam,\n",
    "    showlegend=False,\n",
    "    margin={'t':0,'l':0,'b':0,'r':0},\n",
    ")\n",
    "fig.write_image(tmpdir / \"colmap-scaled.png\", scale=2)\n",
    "f = go.FigureWidget(fig)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.layout['scene']['camera']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ICP + rotation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = cams\n",
    "use_coarse = True\n",
    "scenepts = densepc.replace()\n",
    "masks = []\n",
    "for i, maskinfo in enumerate(masksinfo):\n",
    "    maskpath = Path(maskinfo[\"mask_paths\"][maskinfo[\"best_idx\"]])\n",
    "    maskpath = Path(\"/Users/jerry/Projects/ms-stuff/barrel-playground/barrels/results\") / Path(*maskpath.parts[-4:])\n",
    "    masks.append(np.array(Image.open(maskpath).convert(\"L\")))\n",
    "masks = np.array(masks)\n",
    "objectmesh = mesh.copy()\n",
    "objectsymmetries = get_symmetry_transformations(objinfo[\"barrelsingle-scaled.ply\"], 100)\n",
    "\n",
    "\n",
    "cams = cameras\n",
    "# names, cameras are already assumed to be ordered and filtered\n",
    "# depending on failed registration in COLMAP or SAM masks\n",
    "name2cam = {name: cam for name, cam in zip(names, cameras)}\n",
    "# foundpose results are used as reference for image ids\n",
    "name2imgid = {}\n",
    "name2imgpath = {}\n",
    "obj2cams: v3d.Transform = []\n",
    "# camera for each hypothesis. If multiple hypotheses for each image, there will be\n",
    "# duplicate cameras in here\n",
    "camhyps: v3d.Camera = []\n",
    "# colmap usually can't reconstruct every camera pose, so we can only fit the\n",
    "# foundpose results with a camera pose\n",
    "for fres in foundposeests:\n",
    "    imgpath = Path(fres[\"img_path\"])\n",
    "    name = imgpath.stem\n",
    "    if name not in name2imgid.keys():\n",
    "        name2imgid[name] = fres[\"img_id\"]\n",
    "    if name not in name2imgpath.keys():\n",
    "        name2imgpath[name] = imgpath\n",
    "    # could just use the \"best\" hypothesis. pretty often though, this hypothesis sucks.\n",
    "    # valid_hyp = name in name2cam.keys() and fres[\"hypothesis_id\"] == \"0\"\n",
    "    valid_hyp = name in names\n",
    "    if valid_hyp:\n",
    "        camhyps.append(name2cam[name])\n",
    "        if use_coarse:\n",
    "            R = fres[\"R_coarse\"]\n",
    "            t = fres[\"t_coarse\"]\n",
    "        else:\n",
    "            R = fres[\"R\"]\n",
    "            t = fres[\"t\"]\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = R\n",
    "        T[:3, 3] = np.reshape(t, -1)\n",
    "        obj2cams.append(v3d.Transform.from_matrix(T))\n",
    "obj2cams = dca.stack(obj2cams)\n",
    "camhyps = dca.stack(camhyps)\n",
    "\n",
    "model, inlieridxs = ransac(\n",
    "    camhyps.world_from_cam.matrix4x4,\n",
    "    obj2cams.matrix4x4,\n",
    "    fit_func=fitcams,\n",
    "    loss_func=camloss,\n",
    "    cost_func=camcost,\n",
    "    samp_min=5,\n",
    "    inlier_min=5,\n",
    "    inlier_thres=0.15,\n",
    "    max_iter=50,\n",
    "    seed=0,\n",
    "    relax_on_fail=True,\n",
    ")\n",
    "\n",
    "scalefactor = model.scale\n",
    "camscaled = scale_cams(cams, scalefactor)\n",
    "camhypsscaled = scale_cams(camhyps, scalefactor)\n",
    "obj2worlds = camhypsscaled.world_from_cam @ obj2cams\n",
    "obj2worldsinlier: v3d.Transform = obj2worlds[inlieridxs]\n",
    "\n",
    "sceneptsscaled = scenepts.replace(p=scenepts.p * scalefactor)\n",
    "segidxs = segment_pc_from_masks(sceneptsscaled, masks, camscaled, min_ratio=1/2)\n",
    "\n",
    "# plane fit to seafloor\n",
    "floormask = np.ones(len(sceneptsscaled), dtype=bool)\n",
    "floormask[segidxs] = False\n",
    "plane1 = pyrsc.Plane()\n",
    "best_eq, best_inliers = plane1.fit(sceneptsscaled[floormask].p, thresh=0.005)\n",
    "a, b, c, d = best_eq\n",
    "normal = np.array([a, b, c])\n",
    "R = get_axes_rot([0, 0, 1], normal)\n",
    "planecent = [0, 0, -d / c]\n",
    "Tmat = np.eye(4)\n",
    "Tmat[:3, :3] = R\n",
    "Tmat[:3, 3] = planecent\n",
    "planeT = v3d.Transform.from_matrix(Tmat)\n",
    "camzup = camscaled.apply_transform(planeT.inv)\n",
    "if np.mean(camzup.world_from_cam.t[:, 2]) < 0:\n",
    "    planeT = planeT @ v3d.Transform.from_matrix(np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]]))\n",
    "    camzup = camscaled.apply_transform(planeT.inv)\n",
    "    normal = -normal\n",
    "\n",
    "# 3x points from sfm point cloud\n",
    "meshsamp, _ = trimesh.sample.sample_surface(objectmesh, count=len(segidxs))\n",
    "objinscenepts = sceneptsscaled[segidxs]\n",
    "# simple outlier removal to see if this works\n",
    "o3dobj = o3d.geometry.PointCloud()\n",
    "o3dobj.points = o3d.utility.Vector3dVector(objinscenepts.p)\n",
    "_, inlieridx = o3dobj.remove_statistical_outlier(nb_neighbors=50, std_ratio=2.0)\n",
    "tmpT = []\n",
    "for i, obj2world in enumerate(obj2worldsinlier):\n",
    "    samp_trf = obj2world @ meshsamp\n",
    "    # source is sfm point cloud, since it is incomplete\n",
    "    icpT = v3d.Transform.from_matrix(icp(objinscenepts.p[inlieridx], samp_trf, outlier_std=2.0))\n",
    "    tmpT.append(icpT.inv @ obj2world)\n",
    "    # debug figure (this takes a while to generate)\n",
    "    meshpts = planeT.inv @ v3d.Point3d(p=samp_trf, rgb=[0, 0, 255])\n",
    "    meshicppts = planeT.inv @ v3d.Point3d(p=icpT.inv @ samp_trf, rgb=[0, 255, 0])\n",
    "    sceneobjzuppts = planeT.inv @ objinscenepts[inlieridx]\n",
    "    sceneobjzupoutlierpts = planeT.inv @ objinscenepts[invert_idxs(inlieridx, len(objinscenepts))]\n",
    "    sceneobjzupoutlierpts = sceneobjzupoutlierpts.replace(rgb=[255, 0, 0])\n",
    "    xycent = np.mean(sceneobjzuppts.p, axis=0)[:2]\n",
    "    centT = T_from_translation(-xycent[0], -xycent[1], 0)\n",
    "    icpfig = v3d.make_fig(\n",
    "        [centT @ meshpts, centT @ meshicppts, centT @ sceneobjzuppts, centT @ sceneobjzupoutlierpts],\n",
    "    num_samples_point3d=1000)\n",
    "    # icpfig.write_image(icpdebugdir / f\"icpout_{str(i).zfill(4)}.png\")\n",
    "obj2worldsinlier = dca.stack(tmpT)\n",
    "\n",
    "quatsinlier = quaternion.from_rotation_matrix(obj2worldsinlier.R)\n",
    "ref = quatsinlier[0]\n",
    "quatssymd = [ref]\n",
    "for otherquat in quatsinlier[1:]:\n",
    "    best = closest_quat_sym(ref, otherquat, objectsymmetries)\n",
    "    quatssymd.append(best)\n",
    "quatssymd = np.array(quatssymd)\n",
    "obj2worldsinliersym = obj2worldsinlier.replace(R=quaternion.as_rotation_matrix(quatssymd))\n",
    "\n",
    "qmeanransac, qinliers = ransac(quatssymd, fit_func=qmean, loss_func=qloss, cost_func=qcost, samp_min=5, inlier_min=5, inlier_thres=0.2, max_iter=50, relax_on_fail=True)\n",
    "\n",
    "meanT = v3d.Transform(R=quaternion.as_rotation_matrix(qmeanransac), t=np.mean(obj2worldsinliersym.t, axis=0))\n",
    "quatfig = v3d.make_fig(*get_axes_traces(obj2worldsinliersym, scale=0.5), *get_axes_traces(meanT, linewidth=10))\n",
    "\n",
    "# burial ratio by fitting plane to floor point cloud\n",
    "T_zup = planeT.inv @ meanT\n",
    "meshzup = objectmesh.copy().apply_transform(T_zup.matrix4x4)\n",
    "mesh_zvals = meshzup.vertices[:, 2]\n",
    "zmin, zmax = np.min(mesh_zvals), np.max(mesh_zvals)\n",
    "if zmin >= 0:\n",
    "    burial_ratio_z = 0\n",
    "else:\n",
    "    burial_ratio_z = abs(zmin) / (abs(zmin) + zmax)\n",
    "slicedmesh = trimesh.intersections.slice_mesh_plane(meshzup, [0, 0, 1], [0, 0, 0], cap=True)\n",
    "burial_ratio_vol = 1 - slicedmesh.volume / objectmesh.volume\n",
    "\n",
    "# visualization of fitted scene\n",
    "meshzuppts = v3d.Point3d(p=meshzup.vertices)\n",
    "scenezuppts = planeT.inv @ sceneptsscaled\n",
    "aggfig = v3d.make_fig([scenezuppts, meshzuppts, camzup])\n",
    "\n",
    "plane2camfit = camscaled.world_from_cam.inv @ planeT[..., None]\n",
    "obj2camfit = camscaled.world_from_cam.inv @ meanT[..., None]\n",
    "estposes = []\n",
    "for name, obj2cam, plane2cam in zip(names, obj2camfit, plane2camfit):\n",
    "    posedata = {\n",
    "        \"img_path\": str(name2imgpath[name]),\n",
    "        \"img_id\": name2imgid[name],\n",
    "        \"hypothesis_id\": \"0\",\n",
    "        \"R\": obj2cam.R.tolist(),\n",
    "        \"t\": obj2cam.t.tolist(),\n",
    "        \"R_floor\": plane2cam.R.tolist(),\n",
    "        \"t_floor\": plane2cam.t.tolist(),\n",
    "    }\n",
    "    estposes.append(posedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_trf = obj2world @ meshpc\n",
    "meshpts = planeT.inv @ samp_trf.replace(rgb=[0, 0, 255])\n",
    "meshicppts = planeT.inv @ (icpT.inv @ samp_trf).replace(rgb=[0, 255, 0])\n",
    "sceneobjzuppts = planeT.inv @ objinscenepts[inlieridx]\n",
    "sceneobjzupoutlierpts = planeT.inv @ objinscenepts[invert_idxs(inlieridx, len(objinscenepts))]\n",
    "sceneobjzupoutlierpts = sceneobjzupoutlierpts.replace(rgb=[255, 0, 0])\n",
    "sceneobjzuppts = sceneobjzuppts.replace(rgb=[255, 0, 0])\n",
    "xycent = np.mean(sceneobjzuppts.p, axis=0)[:2]\n",
    "centT = T_from_translation(-xycent[0], -xycent[1], 0)\n",
    "shit = centT @ planeT.inv @ sceneptsscaled[invert_idxs(segidxs, len(sceneptsscaled))]\n",
    "shit = shit.replace(rgb=[255, 200, 200])\n",
    "icpfig = v3d.make_fig(\n",
    "    [centT @ meshpts, centT @ meshicppts, centT @ sceneobjzuppts, centT @ sceneobjzupoutlierpts, shit],\n",
    "num_samples_point3d=1000)\n",
    "icpfig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"icpvis\",\n",
    "        \"width\": None,\n",
    "        \"height\": None,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "icpfig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "icpfig.show(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faintpc = centT @ planeT.inv @ sceneptsscaled\n",
    "faintpc = faintpc.replace(rgb=[255, 200, 200])[::5]\n",
    "trace = faintpc.make_traces()[0].update(marker={\"color\": \"rgba(255, 10, 10, 0.1)\", \"size\": 2})\n",
    "newquatfig = v3d.make_fig(*get_axes_traces(centT @ planeT.inv @ obj2worldsinliersym, scale=0.5), *get_axes_traces(centT @ planeT.inv @ meanT, linewidth=10), trace)\n",
    "newquatfig.update_layout(\n",
    "    showlegend=False,\n",
    ")\n",
    "config = {\n",
    "    \"toImageButtonOptions\": {\n",
    "        \"format\": \"png\", # one of png, svg, jpeg, webp\n",
    "        \"filename\": \"quatavgvis\",\n",
    "        \"width\": None,\n",
    "        \"height\": None,\n",
    "        \"scale\": 1,\n",
    "    }\n",
    "}\n",
    "newquatfig.update_scenes(xaxis_visible=False, yaxis_visible=False, zaxis_visible=False)\n",
    "newquatfig.show(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map of burial fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barrels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
